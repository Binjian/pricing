{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core data utilities\n",
    "\n",
    "> core utilities for data processing: \n",
    "> datetime processing, time zone processing, validity, filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp data.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def validate_datetime(date_string, format_string):\n",
    "    \"\"\"\n",
    "    Validates if a string is a valid datetime according to the given format.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        datetime.strptime(date_string, format_string)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "def validate_datetime_in_iso_format(date_text):\n",
    "        try:\n",
    "            datetime.fromisoformat(date_text)\n",
    "            return True\n",
    "        except ValueError:\n",
    "            # raise ValueError(\"Incorrect data format, should be YYYY-MM-DD\")\n",
    "            return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "date_strings = [\n",
    "    \"2023-12-25 24:00:00\",\n",
    "    \"2023-12-25 12:60:00.12\",\n",
    "    \"2023-12-25 12:10:00\",\n",
    "    \"2023-12-25 23:00:00\",\n",
    "    \"2011-11-04\",\n",
    "    \"20111104\",\n",
    "    \"2011-11-04T00:05:23\",\n",
    "    \"2011-11-04T00:05:23.283185\",\n",
    "    \"20111104T000523\",\n",
    "    \"20111104T000523.283185\",\n",
    "    \"2011-11-04T00:05:23Z\",\n",
    "    \"2011-11-04T00:05:23.283185+08:00\",\n",
    "    \"2011-11-04T00:05:23+08:00\",\n",
    "    ]\n",
    "format_string = \"%Y-%m-%d\"\n",
    "\n",
    "for s in date_strings:\n",
    "    if validate_datetime_in_iso_format(s):\n",
    "        print(f\"{s} is Valid datetime string\")\n",
    "    else:\n",
    "        print(f\"{s} is Invalid datetime string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_datetime_str = pd.DataFrame(date_strings)\n",
    "df_datetime_str.columns = ['datetime']\n",
    "# df_datetime_str\n",
    "df_datetime_str['validity'] = df_datetime_str.apply(lambda x: validate_datetime_in_iso_format(x.iloc[0]), axis=1)\n",
    "df_datetime_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_datetime = df_datetime_str[df_datetime_str.apply(lambda x: validate_datetime_in_iso_format(x.iloc[0]), axis=1)]\n",
    "df_datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_datetime_invalid = df_datetime_str[df_datetime_str.apply(lambda x: not validate_datetime_in_iso_format(x.iloc[0]), axis=1)]\n",
    "df_datetime_invalid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_datetime['datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_datetime_str.apply(lambda x: validate_datetime_in_iso_format(x.iloc[0]), axis=1)\n",
    "df_datetime1 = df_datetime.apply(lambda x: datetime.fromisoformat(x['datetime']), axis=1)\n",
    "df_datetime1.name = 'datetime'\n",
    "df_datetime1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_datetime1.loc[0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_tz = pd.to_datetime(df_datetime1.loc[0:8])\n",
    "df_no_tz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_timezone_abbreviation(timezone_name):\n",
    "    timezone = pytz.timezone(timezone_name)\n",
    "    now = datetime.now(timezone)\n",
    "    return now.strftime(\"%Z\")\n",
    "\n",
    "def validate_timezone_in_iana(timezone_name):\n",
    "    return timezone_name in pytz.all_timezones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "time_zone_strings = [\n",
    "    'Eastern Standard Time',\n",
    "    'Eastern Daylight Time',\n",
    "    'US/Eastern',\n",
    "    'US/Daylight',\n",
    "    'Asia/Shanghai',\n",
    "    'Asia/Mumbai',\n",
    "    'America/New_York',\n",
    "    'Europe/London',\n",
    "    'America/Los_Angeles',\n",
    "    'Asia/Kolkata',\n",
    "    'Europe/London',\n",
    "    'Asia/Hong_Kong',\n",
    "    'Asia/Tokyo',\n",
    "]\n",
    "df_timezone_str = pd.DataFrame(time_zone_strings)\n",
    "df_timezone_str.columns = ['timezone']\n",
    "\n",
    "# df_datetime_str\n",
    "df_timezone_str['validity'] = df_timezone_str.apply(lambda x: validate_timezone_in_iana(x['timezone']), axis=1)\n",
    "df_timezone_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "timezone_fixing_map = {'Eastern Standard Time': 'US/Eastern',\n",
    "                       'Eastern Daylight Time': 'US/Eastern',\n",
    "                       'US/Daylight': 'US/Eastern',\n",
    "                       'Asia/Mumbai': 'Asia/Calcutta',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fix_timezone(timezone_name):\n",
    "    return timezone_fixing_map.get(timezone_name, timezone_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tz in time_zone_strings:\n",
    "    print(f\"{tz} -> {fix_timezone(tz)} -> {get_timezone_abbreviation(fix_timezone(tz))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_timezone_unidentified = df_timezone_str[df_timezone_str.apply(lambda x: not validate_timezone_in_iana(x['timezone']), axis=1)]\n",
    "df_timezone_unidentified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_timezone_unidentified.apply(lambda x: fix_timezone(x['timezone']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_timezone_str['timezone_fixed'] = df_timezone_str.apply(lambda x: fix_timezone(x['timezone']), axis=1)\n",
    "df_timezone_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_timezone = df_timezone_str[df_timezone_str.apply(lambda x: validate_timezone_in_iana(x['timezone_fixed']), axis=1)]\n",
    "df_timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract invalid data\n",
    "df_timezone_invalid = df_timezone_str[df_timezone_str.apply(lambda x: not validate_timezone_in_iana(x.iloc[0]), axis=1)]\n",
    "df_timezone_invalid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_abbr = df_timezone.apply(lambda x: get_timezone_abbreviation(x.loc['timezone_fixed']), axis=1)\n",
    "df_abbr.name = 'abbr'\n",
    "df_abbr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_timezone_str['validity'] = df_timezone_str.apply(lambda x: validate_timezone_in_iana(x.iloc[0]), axis=1)\n",
    "# df_timezone['abbr'] = df_timezone.apply(lambda x: get_timezone_abbreviation(x.iloc[0]), axis=1)\n",
    "# df_timezone.apply(lambda x: get_timezone_abbreviation(x.iloc[0]), axis=1)\n",
    "df_timezone.loc[:,'abbr'] = df_abbr\n",
    "df_timezone\n",
    "# df_timezone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_utc_offset = (df_timezone.apply(lambda x: datetime.now(pytz.timezone(x.loc['timezone_fixed'])), axis=1)\n",
    "                            .apply(lambda x: x.strftime('%z')))\n",
    "df_utc_offset.name = 'utc_offset'\n",
    "df_utc_offset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_timezone.loc[:,'utc_offset'] = df_utc_offset\n",
    "df_timezone\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tz in df_timezone.loc[:,'timezone_fixed']:\n",
    "    print(f\"{tz}: {datetime.now(pytz.timezone(tz))} - {datetime.now(pytz.timezone(tz)).strftime('%Z')}, {datetime.now(pytz.timezone(tz)).strftime('%z')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dt,tz in zip(df_no_tz, df_timezone.loc[:,'timezone_fixed']):\n",
    "    print(f\"{dt}: {dt.tz_localize(tz)}, as {dt.tz_localize(tz).astimezone('utc')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zoneinfo import ZoneInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dt,tz in zip(df_no_tz, df_timezone.loc[:,'timezone_fixed']):\n",
    "    tz_zone = pytz.timezone(tz)\n",
    "    print(f\"{dt}: {tz_zone.localize(dt)}, or {dt.replace(tzinfo=tz_zone)}, or {dt.tz_localize(tz)}, as {dt.tz_localize(tz).astimezone('utc')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert csv to sqlite db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlite_eng = create_engine('sqlite:///../data/price_training_raw.db', echo=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = '../data/bq-results-20240920-103832-1726828742594.csv'\n",
    "chunk_size = 10000\n",
    "total_lines = sum(1 for line in open(csv_file_path))\n",
    "print(total_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(csv_file_path, index_col='dispatch_id', nrows=5)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = np.zeros((2,), dtype=[(\"A\", \"i4\"), (\"B\", \"f4\"), (\"C\", \"U\")])\n",
    "# data\n",
    "\n",
    "# data = np.empty((2,), dtype=[('start','U'), ('end','U')])\n",
    "# data\n",
    "\n",
    "# df = pd.DataFrame(data)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it = pd.read_csv(csv_file_path, index_col='dispatch_id', chunksize=chunk_size)\n",
    "# d = it.get_chunk()\n",
    "# d\n",
    "# df = pd.DataFrame(it.get_chunk())\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in tqdm(pd.read_csv(csv_file_path, index_col='dispatch_id', chunksize=chunk_size), total=total_lines//chunk_size +1):\n",
    "# for chunk in tqdm(pd.read_csv(csv_file_path, chunksize=chunk_size), total=total_lines//chunk_size +1):\n",
    "    data = np.empty((chunk.shape[0],), dtype=[('route_start','U'), ('route_end','U')])\n",
    "    df_append = pd.DataFrame(index=chunk.index, data=data)\n",
    "    chunk = pd.concat([chunk, df_append], axis = 1)\n",
    "    chunk.convert_dtypes()\n",
    "    # chunk.astype({ \n",
    "    #     'ride_id': 'int64',\n",
    "    #     'trip_count': 'int8',\n",
    "    #     'from_utc': 'float64',\n",
    "    #     'from_time_str': 'string',\n",
    "    #     'from_timezone_str': 'string',\n",
    "    #     'to_time_str': 'string',\n",
    "    #     'to_timezone_str': 'string',\n",
    "    #     'passenger_count': 'int8',\n",
    "    #     'luggage_count': 'int8',\n",
    "    #     'children_count': 'int8',\n",
    "    #     'infant_count': 'int8',\n",
    "    #     'distance': 'float64',\n",
    "    #     'duration': 'float64',\n",
    "    #     'trip_no': 'int8',\n",
    "    #     'dispatch_amount': 'float64',\n",
    "    #     'dispatch_currency': 'string',\n",
    "    #     'from_date_str': 'string',\n",
    "    #     'from_time_fix_str': 'string',\n",
    "    #     'from_datetime_fix_str': 'string',\n",
    "    #     'trip_type_id': 'int64',\n",
    "    #     'trip_type': 'string',\n",
    "    #     'ride_status_id': 'int64',\n",
    "    #     'ride_status': 'string',\n",
    "    #     'dispatch_status_id': 'int64',\n",
    "    #     'distpatch_status': 'string',\n",
    "    #     'dispatch_type': 'string',\n",
    "    #     'fleet': 'string',\n",
    "    #     'partner_id': 'int64',\n",
    "    #     'start_place_id': 'int64',\n",
    "    #     'start_place': 'string',\n",
    "    #     'start_lng': 'float64',\n",
    "    #     'start_ltt': 'float64',\n",
    "    #     'end_place_id': 'int64',\n",
    "    #     'end_place': 'string',\n",
    "    #     'end_lng': 'float64',\n",
    "    #     'end_ltt': 'float64',\n",
    "    #     'vehicle_class_id': 'int64',\n",
    "    #     'vehicle_class': 'string',\n",
    "    #     'row_num': 'int64',\n",
    "    #     'route_start': 'string', \n",
    "    #     'route_end': 'string',\n",
    "    #     })\n",
    "    chunk.to_sql('price_training_raw_2024_usd', sqlite_eng, if_exists= 'append',index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert route deduplication result to sqlite db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_result_file_list = ['../data/price_training_raw_2024_usd_start_result_deduplicated.csv',\n",
    "                        '../data/price_training_raw_2024_usd_end_result_deduplicated.csv']\n",
    "csv_result_table_list = ['price_training_raw_2024_usd_start_result_deduplicated',\n",
    "                        'price_training_raw_2024_usd_end_result_deduplicated']\n",
    "\n",
    "chunk_size = 10000\n",
    "total_lines = [sum(1 for line in open(csv_result_file_list[0])),sum(1 for line in open(csv_result_file_list[1]))]\n",
    "print(total_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "sqlite_eng = create_engine('sqlite:///../data/price_training_raw.db', echo=False)\n",
    "\n",
    "sample = pd.read_csv(csv_result_file_list[1], index_col='dispatch_id', nrows=5)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(2):\n",
    "    for chunk in tqdm(pd.read_csv(csv_result_file_list[t], index_col='dispatch_id', chunksize=chunk_size),\n",
    "                      total=total_lines[t] // chunk_size + 1):\n",
    "        # for chunk in tqdm(pd.read_csv(csv_file_path, chunksize=chunk_size), total=total_lines//chunk_size +1):\n",
    "        chunk.to_sql(csv_result_table_list[t], sqlite_eng, if_exists='append', index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the union of the label tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from sqlalchemy import MetaData, create_engine, asc, desc, and_, or_, not_, case, extract, cast, Numeric, text, distinct, Column, update, bindparam\n",
    "from sqlalchemy.types import DateTime, Date, Time, String\n",
    "from sqlalchemy.schema import *\n",
    "from sqlalchemy.sql import func as F, Selectable, select, union\n",
    "from sqlalchemy.dialects import registry\n",
    "from sqlalchemy.engine.row import Row\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy.orm import sessionmaker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_eng = create_engine('sqlite:///../data/price_training_raw.db', echo=False)\n",
    "conn = sql_eng.connect()\n",
    "metadata = MetaData()\n",
    "Session = sessionmaker(bind=sql_eng)\n",
    "session = Session()\n",
    "chunk_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['price_training_raw_2024_usd_start_result_deduplicated',\n",
    "              'price_training_raw_2024_usd_end_result_deduplicated',\n",
    "              'price_training_raw_2024_usd_route_label_deduplicated',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_start_t = Table(label_list[0], metadata, autoload_with=sql_eng)\n",
    "print(session.query(label_start_t).count())\n",
    "label_end_t = Table(label_list[1], metadata, autoload_with=sql_eng)\n",
    "print(session.query(label_end_t).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_start_q = session.query(label_start_t)\n",
    "label_start_q.count()\n",
    "label_end_q = session.query(label_end_t)\n",
    "label_end_q.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_start_t.columns.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_routes_q = union(label_start_q, label_end_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(label_routes_q, sql_eng)\n",
    "# {l:r for l,r in zip(df.columns,label_start_t.columns.keys())}\n",
    "df.columns = label_start_t.columns.keys()\n",
    "# df.index = df['dispatch_id']\n",
    "df.set_index(['start_ltt_lp', 'start_lng_lp', 'end_ltt_lp', 'end_lng_lp'], inplace=True)\n",
    "# df.set_index('dispatch_id', inplace=True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.sort_values(['start_ltt_lp', 'start_lng_lp', 'end_ltt_lp', 'end_lng_lp'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql(label_list[2], sqlite_eng, if_exists='append', index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision reduction for start_ltt, start_lng, end_ltt, end_lng and pick distinct values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from sqlalchemy import create_engine, select, func, distinct, MetaData, Table, update, bindparam, Column, insert, desc, asc, and_, or_, not_, Numeric, cast, func\n",
    "from sqlalchemy.orm import sessionmaker, aliased\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_eng = create_engine('sqlite:///../data/price_training_raw.db', echo=False)\n",
    "conn = sql_eng.connect()\n",
    "my_table = Table('price_training_raw_2024_usd', MetaData(), autoload_with=sql_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = select(func.count(distinct(my_table.c.dispatch_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sql_eng.connect() as connection:\n",
    "    result = connection.execute(query)\n",
    "    unique_count = result.scalar()\n",
    "    \n",
    "print(unique_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = select(my_table).limit(10)\n",
    "df = pd.read_sql(query, conn, index_col='dispatch_id')\n",
    "# df[['route_start','route_end']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# order by start_ltt, start_lng, end_ltt, end_lng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_eng = create_engine('sqlite:///../data/price_training_raw.db', echo=False)\n",
    "conn = sql_eng.connect()\n",
    "metadata = MetaData()\n",
    "my_table = Table('price_training_raw_2024_usd', metadata, autoload_with=sql_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.reflect(bind=sql_eng)\n",
    "raw_t = metadata.tables['price_training_raw_2024_usd']\n",
    "s = select(raw_t).limit(10)\n",
    "rp = sql_eng.connect().execute(s)\n",
    "df = pd.DataFrame(rp)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_columns = [Column(col.name, col.type, primary_key=col.primary_key) for col in my_table.columns]\n",
    "# new_table = Table('price_training_raw_2024_usd_reordered', metadata, *new_columns)\n",
    "# new_table.create(sql_eng)\n",
    "new_table = Table('price_training_raw_2024_usd_reordered', metadata, autoload_with=sql_eng)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Session = sessionmaker(bind=sql_eng)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create new table with latitutde and longitude reduced to 5 decimal places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_t = select(my_table).where(\n",
    "    and_(\n",
    "        my_table.c.start_ltt.isnot(None),\n",
    "        my_table.c.start_lng.isnot(None),\n",
    "    )\n",
    ").order_by(asc(my_table.c.start_ltt), asc(my_table.c.start_ltt))\n",
    "ordered_t = ordered_t.select_from(my_table)\n",
    "ordered_t = ordered_t.alias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordered_t = ordered_t.limit(10)\n",
    "# df = pd.read_sql(ordered_t,sql_eng)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_ltt_lng_t = select(ordered_t.c.dispatch_id,\n",
    "                      cast(ordered_t.c.start_ltt, Numeric(9,5)).label('start_ltt_lp'),\n",
    "                      cast(ordered_t.c.start_lng, Numeric(9,5)).label('start_lng_lp'),\n",
    "                      cast(ordered_t.c.end_ltt, Numeric(9,5)).label('end_ltt_lp'),\n",
    "                      cast(ordered_t.c.end_lng, Numeric(9,5)).label('end_lng_lp'))\n",
    "lp_ltt_lng_t = lp_ltt_lng_t.select_from(ordered_t)\n",
    "lp_ltt_lng_t = lp_ltt_lng_t.alias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_sql(lp_ltt_lng_t, sql_eng)\n",
    "# df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "distinct_start_lp_t = select(lp_ltt_lng_t.c.dispatch_id, \n",
    "                         lp_ltt_lng_t.c.start_ltt_lp,\n",
    "                         # func.max(lp_ltt_lng_t.c.start_ltt_lp).label('unique_start_ltt_lp'), \n",
    "                         # func.max(lp_ltt_lng_t.c.start_lng_lp).label('unique_start_lng_lp'),\n",
    "                         lp_ltt_lng_t.c.start_lng_lp, \n",
    "                         lp_ltt_lng_t.c.end_ltt_lp,\n",
    "                         lp_ltt_lng_t.c.end_lng_lp\n",
    "                         ).group_by(lp_ltt_lng_t.c.start_ltt_lp).distinct(lp_ltt_lng_t.c.start_lng_lp)#.subquery()\n",
    "# distinct_subq_t = distinct_subq_t.limit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df = pd.read_sql(distinct_start_lp_t, sql_eng)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "distinct_end_lp_t = select(lp_ltt_lng_t.c.dispatch_id, \n",
    "                         lp_ltt_lng_t.c.start_ltt_lp,\n",
    "                         lp_ltt_lng_t.c.end_ltt_lp,\n",
    "                         lp_ltt_lng_t.c.end_lng_lp\n",
    "                         ).group_by(lp_ltt_lng_t.c.end_ltt_lp).distinct(lp_ltt_lng_t.c.end_lng_lp)\n",
    "distinct_end_lp_t = distinct_end_lp_t.alias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df = pd.read_sql(distinct_end_lp_t, sql_eng)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# distinct_t = select(distinct(lp_ltt_lng_t.c.start_lng_lp))\n",
    "# distinct_t = distinct_t.limit(1000)#.distinct(lp_ltt_lng_t.c.start_ltt)\n",
    "# df = pd.read_sql(distinct_t, sql_eng)\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new table with ordered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_t = select(my_table).where(\n",
    "    and_(\n",
    "        my_table.c.start_ltt.isnot(None),\n",
    "        my_table.c.start_lng.isnot(None),\n",
    "    )\n",
    ").order_by(asc(my_table.c.start_ltt), asc(my_table.c.start_ltt))\n",
    "ordered_t = ordered_t.select_from(my_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sql_eng.connect() as conn:\n",
    "    result = conn.execute(ordered_t)\n",
    "    ordered_rows = result.fetchall()\n",
    "# ordered_rows[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ordered_rows[:10]\n",
    "cols = [c.name for c in ordered_t.subquery().columns]\n",
    "df = pd.DataFrame(data=data, columns=cols)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = [dict(zip(cols, row)) for row in data]\n",
    "batch[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query FP-Server and add label to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = session.execute(\n",
    "    insert(new_table).values(batch)\n",
    ")\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 1000\n",
    "total_rows = len(ordered_rows)\n",
    "total_rows\n",
    "total = total_rows//chunk_size+1\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for chunk in tqdm(range(total), total=total, desc='Overall Processing'):\n",
    "    start = chunk*chunk_size\n",
    "    end = (chunk+1)*chunk_size\n",
    "    if end > total_rows:\n",
    "        end = total_rows\n",
    "    chunk_data = ordered_rows[start:end]\n",
    "    batch = [dict(zip(cols,row)) for row in chunk_data] \n",
    "    result = session.execute(insert(new_table).values(batch))\n",
    "    session.commit()\n",
    "    # for row in tqdm(chunk_data, total=len(chunk_data), desc='Chunk Processing'):\n",
    "    #     session.execute(new_table.insert().values(row))\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=ordered_rows)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in tqdm(result, total=unique_count):\n",
    "    for chunk in tqdm(pd.read_sql(query.statement, conn, index_col='dispatch_id', chunksize=chunk_size), total=total_rows//chunk_size+1, desc='Overall Processing'):\n",
    "    route_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sql_eng.connect() as conn:\n",
    "    result = conn.execute(ordered_t)\n",
    "    for row in tqdm(result, total=unique_count):\n",
    "        session.execute(new_table.insert().values(row))\n",
    "    session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(my_table.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata_new = MetaData()\n",
    "# my_table.to_metadata(metadata_new)\n",
    "# metadata_new.tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_table = Table('price_training_raw_2024_usd_geo_ordered', metadata, *my_table.columns)\n",
    "# list(new_table.columns)\n",
    "# new_table.name = 'price_training_raw_2024_usd_geo_ordered'\n",
    "# metadata_new.create_all(sql_eng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reduce precision of start_ltt, start_lng, end_ltt, end_lng by 3 digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'route_start'] = 'start'\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stmt = (\n",
    "    update(my_table)  # 'raw' is your table object\n",
    "    .where(my_table.c.dispatch_id == 822019)\n",
    "    .values(\n",
    "        route_start='New Zone C',\n",
    "        route_end='New Zone D'\n",
    "    )\n",
    ")\n",
    "print(stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled = stmt.compile()\n",
    "compiled.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sql_eng.connect() as conn:\n",
    "    result = conn.execute(stmt)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = select(my_table).where(my_table.c.dispatch_id == 822019)\n",
    "rp = sql_eng.connect().execute(s)\n",
    "results = rp.fetchall()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,r in df.iterrows():\n",
    "    l = [i, r['ride_id'], r['dispatch_amount'],r['fleet']]\n",
    "    # print(r)\n",
    "    df.at[i,'route_end'] = 'Shanghai'\n",
    "    stmt = (\n",
    "        update(my_table)\n",
    "        .where(my_table.c.dispatch_id == int(i))\n",
    "        .values(\n",
    "            route_start='Beijing',\n",
    "            route_end='Shanghai',\n",
    "        )\n",
    "    )\n",
    "    with sql_eng.connect() as conn:\n",
    "        conn.execute(stmt)\n",
    "        conn.commit()\n",
    "    # print('----')\n",
    "    print(l)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update data batchwise in sqlite db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'route_start'] = 'Zone 0'\n",
    "df.loc[:,'route_end'] = 'Zone 1'\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = (\n",
    "    update(my_table)  # 'raw' is your table object\n",
    "    .where(my_table.c.dispatch_id == bindparam('b_dispatch_id'))\n",
    "    .values(\n",
    "        route_start=bindparam('route_start'),\n",
    "        route_end=bindparam('route_end')\n",
    "    )\n",
    ")\n",
    "print(stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [ \n",
    "            {'dispatch_id': i,\n",
    "             'route_start': r['route_start'],\n",
    "             'route_end': r['route_end']} \n",
    "            for i,r in df.iterrows()\n",
    "        ]\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with sql_eng.begin() as conn:\n",
    "    conn.execute(\n",
    "        stmt,\n",
    "        [ \n",
    "            {'b_dispatch_id': i,\n",
    "             'route_start': r['route_start'],\n",
    "             'route_end': r['route_end']} \n",
    "            for i,r in df.iterrows()\n",
    "        ],\n",
    "    )\n",
    "    conn.commit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = select(my_table).limit(20)\n",
    "rp = sql_eng.connect().execute(s)\n",
    "results = rp.fetchall()\n",
    "df = pd.DataFrame(results)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,r in df.iterrows():\n",
    "    print(i, r['ride_id'], r['dispatch_amount'],r['fleet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df.to_sql('price_training_raw_2024_usd', sqlite_eng, if_exists= 'replace',index=True, index_label='dispatch_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for r in df.itertuples():\n",
    "    # print(r)\n",
    "    print(r.ride_id, r.fleet)\n",
    "    df.at[r.Index, 'route_start'] = 'PVG'\n",
    "    # r.route_start = 'start'\n",
    "    # r.route_end = 'end'\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df.to_sql('price_training_raw_2024_usd', sqlite_eng, if_exists= 'replace',index=True, index_label='dispatch_id')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
