{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data database scraper\n",
    "> database scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp data.database.scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from pyasn1_modules.rfc3279 import id_fieldType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from sqlalchemy import MetaData, create_engine, asc, desc, and_, or_, not_, case, extract, cast, text, distinct\n",
    "from sqlalchemy.types import DateTime, Date, Time\n",
    "from sqlalchemy.schema import *\n",
    "from sqlalchemy.sql import func as F, Selectable, select\n",
    "from sqlalchemy.dialects import registry\n",
    "from sqlalchemy.engine.row import Row\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy.orm import sessionmaker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import requests\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from google.oauth2 import service_account\n",
    "from google.oauth2.service_account import Credentials\n",
    "from geopy.timezone import from_timezone_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from google.cloud import bigquery\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = os.getenv('GC_QUOTE_API_CREDENTIALS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credential = service_account.Credentials.from_service_account_file(\"../\" + key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registry.register('bigquery', 'sqlalchemy_bigquery', 'BigQueryDialect')\n",
    "engine = create_engine('bigquery://quote-api-365206',\n",
    "                       credentials_path='../' + key,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Session = sessionmaker(bind=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = MetaData()\n",
    "def get_table(project_name: str, dataset_name: str, table_name: str)-> Table:\n",
    "    table = Table(f'{project_name}.{dataset_name}.{table_name}', metadata, autoload_with=engine)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find all tables in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ride_trip_t = get_table('elife-data-warehouse-prod','ods', 'ride_trip').alias()\n",
    "ride_dispatch_t = get_table('elife-data-warehouse-prod','ods', 'ride_dispatch').alias()\n",
    "ride_enum_t = get_table('elife-data-warehouse-prod','ods', 'ride_enum').alias()\n",
    "ride_ride_t = get_table('elife-data-warehouse-prod','ods', 'ride_ride').alias()\n",
    "ride_partner_tran_t = get_table('elife-data-warehouse-prod','ods', 'ride_partner_tran').alias()\n",
    "ride_partner_t = get_table('elife-data-warehouse-prod','ods', 'ride_partner').alias()\n",
    "dim_place_t = get_table('elife-data-warehouse-prod','dim', 'dim_place').alias()\n",
    "ride_vehicle_class_t = get_table('elife-data-warehouse-prod','ods', 'ride_vehicle_class').alias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auction_ride_t = get_table('elife-data-warehouse-prod','ods', 'ride_auction_ride').alias()\n",
    "auction_fleet_t = get_table('elife-data-warehouse-prod','ods', 'ride_auction_fleet').alias()\n",
    "ride_fleet_t = get_table('elife-data-warehouse-prod','ods', 'ride_fleet').alias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_type_id_t = select(ride_dispatch_t.c.ride_id, ride_trip_t.c.trip_type.label('trip_type_id'))\n",
    "trip_type_id_t = trip_type_id_t.select_from(ride_dispatch_t\n",
    "                                      .join(ride_trip_t, ride_dispatch_t.c.ride_id == ride_trip_t.c.ride_id))\n",
    "trip_type_id_t = trip_type_id_t.alias()\n",
    "                  \n",
    "# trip_type_id_t = trip_type_id_t.limit(10)\n",
    "# df = pd.read_sql(trip_type_id_t, engine\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# trip_type_id_q = session.query(trip_type_id_t).limit(10)\n",
    "# # for trip in trip_type_id_q:\n",
    "#     print(trip)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_type_t = select(trip_type_id_t.c.ride_id, trip_type_id_t.c.trip_type_id, ride_enum_t.c.name.label('trip_type'))\n",
    "trip_type_t = trip_type_t.select_from(trip_type_id_t\n",
    "                                      .join(ride_enum_t, trip_type_id_t.c.trip_type_id == ride_enum_t.c.id, isouter=True))\n",
    "trip_type_t = trip_type_t.alias()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ride_status_t = select(ride_ride_t.c.id.label('ride_id'), ride_ride_t.c.stat.label('ride_status_id'), ride_enum_t.c.name.label('ride_status'))\n",
    "ride_status_t = ride_status_t.select_from(ride_ride_t\n",
    "                                          .join(ride_enum_t, ride_ride_t.c.stat == ride_enum_t.c.id, isouter=True))\n",
    "ride_status_t = ride_status_t.alias()\n",
    "# ride_status_t = ride_status_t.limit(10)\n",
    "# df = pd.read_sql(ride_status_t, engine)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ride_datetime_t = select(ride_ride_t.c.id.label('ride_id'), \n",
    "                         F.substring(ride_ride_t.c.from_time_str, 1, 10).label('from_date_str'),\n",
    "                         F.concat(F.substring(ride_ride_t.c.from_time_str, 12, 16),':00').label('from_time_fix_str'),\n",
    "                         F.concat(F.substring(ride_ride_t.c.from_time_str, 1, 10), \n",
    "                                  ' ', \n",
    "                                  F.substring(ride_ride_t.c.from_time_str, 12, 16),\n",
    "                                  ':00'\n",
    "                                  ).label('from_datetime_fix_str'),\n",
    "                         extract(\n",
    "                             'DAYOFWEEK',\n",
    "                             cast(F.concat(F.substring(ride_ride_t.c.from_time_str, 1, 10),\n",
    "                                       ' ',\n",
    "                                       F.substring(ride_ride_t.c.from_time_str, 12, 16),\n",
    "                                       ':00'\n",
    "                                       ),\n",
    "                              DateTime)\n",
    "                         ).label('day_of_week_local'),\n",
    "                         extract(\n",
    "                             'DAYOFWEEK',\n",
    "                             cast(F.timestamp_seconds(ride_ride_t.c.from_utc), \n",
    "                                  DateTime)\n",
    "                         ).label('day_of_week_utc'),\n",
    "                         F.datetime(F.timestamp_seconds(ride_ride_t.c.from_utc)).label('from_datetime_utc'),\n",
    "                         ride_ride_t.c.from_timezone_str,\n",
    "                         # F.current_date(ride_ride_t.c.from_timezone_str).label('current_date'),\n",
    "                         #cast(ride_ride_t.c.from_time_str,DateTime).label('from_datetime'),\n",
    "                         #cast(F.concat(F.substring(ride_ride_t.c.from_time_str, 1, 10), 'T', F.substring(ride_ride_t.c.from_time_str, 12, 16)),DateTime).label('from_datetime'),\n",
    "                         #cast(ride_ride_t.c.from_time_str, DateTime).label('from_time_dt'),\n",
    "                         # F.timezone(ride_ride_t.c.from_timezone_str, cast(ride_ride_t.c.from_time_str, DateTime).label('from_time_dt')),\n",
    "                         )                  \n",
    "ride_datetime_t = ride_datetime_t.select_from(ride_ride_t)\n",
    "ride_datetime_t = ride_datetime_t.alias()\n",
    "# ride_datetime_t = ride_datetime_t.limit(100)\n",
    "# df = pd.read_sql(ride_datetime_t, engine)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch_status_t = select(ride_dispatch_t.c.id.label('ride_id'), ride_dispatch_t.c.stat.label('dispatch_status_id'), ride_enum_t.c.name.label('distpatch_status'))\n",
    "dispatch_status_t = dispatch_status_t.select_from(ride_dispatch_t\n",
    "                                          .join(ride_enum_t, ride_dispatch_t.c.stat == ride_enum_t.c.id, isouter=True))\n",
    "dispatch_status_t = dispatch_status_t.alias()\n",
    "#dispatch_status_t = dispatch_status_t.limit(10)\n",
    "#df = pd.read_sql(dispatch_status_t, engine)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auction_type_t = select(\n",
    "    auction_ride_t.c.ride_id.label('ride_id'),\n",
    "    auction_ride_t.c.auction_id.label('auction_id'),\n",
    "    auction_fleet_t.c.fleet_id.label('auction_fleet_id'),\n",
    "    ride_dispatch_t.c.to_fleet_id.label('dispatch_fleet_id'),\n",
    "    ride_fleet_t.c.name.label('fleet'),\n",
    "    case(\n",
    "        (ride_dispatch_t.c.to_fleet_id == auction_fleet_t.c.fleet_id, 'auction'),\n",
    "        else_ = 'dispatch',\n",
    "    ).label('dispatch_type')\n",
    ")\n",
    "auction_type_t = auction_type_t.select_from(auction_ride_t\n",
    "                                            .join(auction_fleet_t, auction_ride_t.c.auction_id == auction_fleet_t.c.auction_id, isouter=True)\n",
    "                                            .join(ride_dispatch_t, auction_ride_t.c.ride_id == ride_dispatch_t.c.ride_id, isouter=True)\n",
    "                                            .join(ride_fleet_t, ride_dispatch_t.c.to_fleet_id == ride_fleet_t.c.id, isouter=True))\n",
    "auction_type_t = auction_type_t.alias()\n",
    "# auction_type_t = auction_type_t.limit(100)\n",
    "# df = pd.read_sql(auction_type_t, engine)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch_type_t = (select(\n",
    "    ride_dispatch_t.c.id.label('ride_id'),\n",
    "    ride_dispatch_t.c.to_fleet_id.label('dispatch_fleet_id'),\n",
    "    auction_ride_t.c.auction_id.label('auction_id'),\n",
    "    auction_fleet_t.c.fleet_id.label('auction_fleet_id'),\n",
    "    case(\n",
    "        (ride_dispatch_t.c.to_fleet_id == auction_fleet_t.c.fleet_id, 'auction'), \n",
    "        else_ = 'dispatch',\n",
    "    ).label('dispatch_type'),\n",
    "    ride_fleet_t.c.name.label('fleet')\n",
    "))\n",
    "# .where(\n",
    "#     ride_dispatch_t.c.to_fleet_id == auction_fleet_t.c.fleet_id\n",
    "# ))\n",
    "dispatch_type_t = dispatch_type_t.select_from(ride_dispatch_t\n",
    "                                          .join(auction_ride_t, ride_dispatch_t.c.ride_id == auction_ride_t.c.ride_id, isouter=True)\n",
    "                                          .join(auction_fleet_t, auction_ride_t.c.auction_id == auction_fleet_t.c.auction_id, isouter=True)\n",
    "                                          .join(ride_fleet_t, ride_dispatch_t.c.to_fleet_id == ride_fleet_t.c.id, isouter=True))\n",
    "dispatch_type_t = dispatch_type_t.alias()\n",
    "# dispatch_type_t = dispatch_type_t.limit(100)\n",
    "# df = pd.read_sql(dispatch_type_t, engine)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partner_id_t = select(ride_ride_t.c.id.label('ride_id'), ride_partner_tran_t.c.partner_id.label('partner_id'))\n",
    "partner_id_t = partner_id_t.select_from(ride_ride_t\n",
    "                                        .join(ride_partner_tran_t, ride_ride_t.c.partner_tran_id == ride_partner_tran_t.c.id, isouter=True))\n",
    "partner_id_t = partner_id_t.alias()\n",
    "#partner_id_t = partner_id_t.limit(10)\n",
    "#df = pd.read_sql(partner_id_t, engine)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partner_t = select(partner_id_t.c.ride_id, partner_id_t.c.partner_id, ride_partner_t.c.name.label('partner'))\n",
    "partner_t = partner_t.select_from(partner_id_t\n",
    "                                  .join(ride_partner_t, partner_id_t.c.partner_id == ride_partner_t.c.id, isouter=True))\n",
    "partner_t = partner_t.alias()\n",
    "# partner_t = partner_t.limit(10)\n",
    "# df = pd.read_sql(partner_t,engine)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_place_t = select(ride_ride_t.c.id.label('ride_id'), \n",
    "                      ride_ride_t.c.from_place_id.label('start_place_id'), \n",
    "                      dim_place_t.c.name.label('start_place'), \n",
    "                      dim_place_t.c.lng.label('lng'), \n",
    "                      dim_place_t.c.lat.label('ltt'),\n",
    "                      )\n",
    "from_place_t = from_place_t.select_from(ride_ride_t\n",
    "                                        .join(dim_place_t, ride_ride_t.c.from_place_id == dim_place_t.c.id, isouter=True))\n",
    "from_place_t = from_place_t.alias()\n",
    "#from_place_t = from_place_t.limit(10)\n",
    "#df = pd.read_sql(from_place_t, engine)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_place_t = select(ride_ride_t.c.id.label('ride_id'), \n",
    "                      ride_ride_t.c.to_place_id.label('end_place_id'), \n",
    "                      dim_place_t.c.name.label('end_place'), \n",
    "                      dim_place_t.c.lng.label('lng'), \n",
    "                      dim_place_t.c.lat.label('ltt'))\n",
    "to_place_t = to_place_t.select_from(ride_ride_t\n",
    "                                        .join(dim_place_t, ride_ride_t.c.to_place_id == dim_place_t.c.id, isouter=True))\n",
    "to_place_t = to_place_t.alias()\n",
    "#to_place_t = to_place_t.limit(10)\n",
    "#df = pd.read_sql(to_place_t, engine)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_class_t = select(ride_ride_t.c.id.label('ride_id'),\n",
    "                         ride_ride_t.c.vehicle_class_id.label('vehicle_class_id'), \n",
    "                         ride_vehicle_class_t.c.name.label('vehicle_class'))\n",
    "vehicle_class_t = vehicle_class_t.select_from(ride_ride_t\n",
    "                                              .join(ride_vehicle_class_t, ride_ride_t.c.vehicle_class_id == ride_vehicle_class_t.c.id, isouter=True))\n",
    "vehicle_class_t = vehicle_class_t.alias()\n",
    "#vehicle_class_t = vehicle_class_t.limit(10)\n",
    "#df = pd.read_sql(vehicle_class_t, engine)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_from_date = '2024-01-01'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_training_t = select(ride_ride_t.c.id.label('ride_id'),\n",
    "                          ride_ride_t.c.trip_count,\n",
    "                          ride_ride_t.c.from_utc,\n",
    "                          ride_ride_t.c.from_time_str,\n",
    "                          ride_ride_t.c.from_timezone_str,\n",
    "                          ride_ride_t.c.to_time_str,\n",
    "                          ride_ride_t.c.to_timezone_str,\n",
    "                          ride_ride_t.c.passenger_count,\n",
    "                          ride_ride_t.c.luggage_count,\n",
    "                          ride_ride_t.c.children_count,\n",
    "                          ride_ride_t.c.infant_count,\n",
    "                          ride_ride_t.c.distance,\n",
    "                          ride_ride_t.c.duration,\n",
    "                          ride_dispatch_t.c.id.label('dispatch_id'),\n",
    "                          ride_dispatch_t.c.trip_no,\n",
    "                          ride_dispatch_t.c.amount.label('dispatch_amount'),\n",
    "                          ride_dispatch_t.c.currency.label('dispatch_currency'),\n",
    "                          ride_datetime_t.c.from_date_str,\n",
    "                          ride_datetime_t.c.from_time_fix_str,\n",
    "                          ride_datetime_t.c.from_datetime_fix_str,\n",
    "                          # ride_datetime_t.c.day_of_week,\n",
    "                          # text(\"EXTRACT(DAYOFWEEK FROM TIMESTAMP_SECONDS(ride_ride_t.from_utc))\").label('day_of_week'),\n",
    "                          trip_type_t.c.trip_type_id,\n",
    "                          trip_type_t.c.trip_type,\n",
    "                          ride_status_t.c.ride_status_id,\n",
    "                          ride_status_t.c.ride_status,\n",
    "                          dispatch_status_t.c.dispatch_status_id,\n",
    "                          dispatch_status_t.c.distpatch_status,\n",
    "                          dispatch_type_t.c.dispatch_type,\n",
    "                          ride_fleet_t.c.name.label('fleet'),\n",
    "                          partner_t.c.partner_id,\n",
    "                          partner_t.c.partner,\n",
    "                          from_place_t.c.start_place_id,\n",
    "                          from_place_t.c.start_place,\n",
    "                          from_place_t.c.lng.label('start_lng'),\n",
    "                          from_place_t.c.ltt.label('start_ltt'),\n",
    "                          to_place_t.c.end_place_id,\n",
    "                          to_place_t.c.end_place,\n",
    "                          to_place_t.c.lng.label('end_lng'),\n",
    "                          to_place_t.c.ltt.label('end_ltt'),\n",
    "                          vehicle_class_t.c.vehicle_class_id,\n",
    "                          vehicle_class_t.c.vehicle_class,\n",
    "                          ).where(\n",
    "                              and_(\n",
    "                                  ride_ride_t.c.from_time_str > data_from_date,\n",
    "                                  or_(\n",
    "                                    ride_dispatch_t.c.currency == 'USD',\n",
    "                                    # ride_dispatch_t.c.currency == 'CNY',\n",
    "                                  ),\n",
    "                                  # vehicle_class_t.c.vehicle_class== 'MPV-5',\n",
    "                                  # or_ (dispatch_type_t.c.dispatch_type == 'auction',\n",
    "                                  #      dispatch_type_t.c.dispatch_type == 'dispatch'),\n",
    "                                  # F.lower(from_place_t.c.start_place).like('%orlando%'),\n",
    "                                  # F.lower(to_place_t.c.end_place).like('%orlando%'),\n",
    "                                  \n",
    "                                  # not_(ride_datetime_t.c.day_of_week.in_([1, 7])),\n",
    "                                  # not_(ride_ride_t.c.from_time_str.in_(exclude_dates)),\n",
    "                              )\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "price_training_t = price_training_t.select_from(ride_ride_t\n",
    "                                                .join(ride_dispatch_t, ride_ride_t.c.id == ride_dispatch_t.c.ride_id)\n",
    "                                                .join(ride_datetime_t, ride_ride_t.c.id == ride_datetime_t.c.ride_id)\n",
    "                                                .join(trip_type_t, ride_ride_t.c.id == trip_type_t.c.ride_id, isouter=True)\n",
    "                                                .join(ride_status_t, ride_ride_t.c.id == ride_status_t.c.ride_id, isouter=True)\n",
    "                                                .join(dispatch_status_t, ride_ride_t.c.id == dispatch_status_t.c.ride_id, isouter=True)\n",
    "                                                .join(dispatch_type_t, ride_ride_t.c.id == dispatch_type_t.c.ride_id, isouter=True)\n",
    "                                                .join(partner_t, ride_ride_t.c.id == partner_t.c.ride_id, isouter=True)\n",
    "                                                .join(from_place_t, ride_ride_t.c.id == from_place_t.c.ride_id, isouter=True)\n",
    "                                                .join(to_place_t, ride_ride_t.c.id == to_place_t.c.ride_id, isouter=True)\n",
    "                                                .join(vehicle_class_t, ride_ride_t.c.id == vehicle_class_t.c.ride_id, isouter=True)\n",
    "                                                .join(ride_fleet_t, ride_dispatch_t.c.to_fleet_id == ride_fleet_t.c.id, isouter=True)\n",
    "                                                ).distinct(ride_dispatch_t.c.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# price_training_t = price_training_t.alias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(price_training_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sql_with_progress(query, engine, chunksize=1000):\n",
    "    with tqdm(total=None, desc=\"Reading SQL\") as pbar:\n",
    "        df = pd.DataFrame()\n",
    "        for chunk in pd.read_sql(query, engine, chunksize=chunksize):\n",
    "            df = pd.concat([df, chunk], ignore_index=True)\n",
    "            pbar.update(len(chunk))\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk = pd.read_sql(price_training_t,engine, chunksize=100)\n",
    "# df = pd.concat(chunk, ignore_index=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_rides = read_sql_with_progress(price_training_t, engine, chunksize=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_gbq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_rides = pandas_gbq.read_gbq(price_training_t, credentials=credential, progress_bar_type='tqdm_notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use ORM to retrieve records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_count = session.query(F.count(price_training_t.c.ride_id)).scalar()\n",
    "print(sample_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://j1j495o5pk.execute-api.us-east-2.amazonaws.com/upncoming/ride-pricings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# params = {\n",
    "#     'from_lat': 37.61911449999999,\n",
    "#     'from_lng':-122.3816274,\n",
    "#     'to_lat':37.3635295,\n",
    "#     'to_lng':-121.9285932,\n",
    "#     'from_utc':1727352000,\n",
    "# }\n",
    "# response = requests.get(url=url, params=params)\n",
    "# response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = response.json()\n",
    "# fix_price_zones = res['fleets'][0]['vehicle_classes'][0]['price_detail']['base_pricing']['fix_price_detail']\n",
    "# print(fix_price_zones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ride_samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pt = price_training_q.first()\n",
    "# pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     'from_lat': (pt._mapping['start_ltt']),\n",
    "#     'from_lng': (pt._mapping['start_lng']),\n",
    "#     'to_lat': (pt._mapping['end_ltt']),\n",
    "#     'to_lng': (pt._mapping['end_lng']),\n",
    "#     # 'from_utc': int(pt._mapping['from_utc']),\n",
    "# }\n",
    "# params\n",
    "\n",
    "# response = requests.get(url=url, params=params)\n",
    "# res = response.json()\n",
    "# res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import String,Integer,insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sqlite_metadata = MetaData()\n",
    "# fixed_zone_routes = Table('fixed_zone_routes', sqlite_metadata,\n",
    "#                           Column('start', String),\n",
    "#                           Column('end', String),\n",
    "#                           Column('dispatch_id', Integer),\n",
    "#                           )\n",
    "sqlite_eng = create_engine('sqlite:///../data/dispatch_fix_zones.db', echo=False)\n",
    "connection = sqlite_eng.connect()\n",
    "sqlite_metadata.create_all(sqlite_eng)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "price_training_q = session.query(price_training_t).limit(500)\n",
    "fix_zone_routes_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "j = 0\n",
    "for pt in price_training_q:\n",
    "    # print('1')\n",
    "    # ride_samples.append(pt)\n",
    "    params = {\n",
    "        'from_lat': pt._mapping['start_ltt'],\n",
    "        'from_lng': pt._mapping['start_lng'],\n",
    "        'to_lat': pt._mapping['end_ltt'],\n",
    "        'to_lng': pt._mapping['end_lng'],\n",
    "        # 'from_utc':pt._mapping['from_utc'],\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url=url, params=params)\n",
    "    except requests.exceptions.Timeout:\n",
    "        print('Timeout')\n",
    "        continue\n",
    "    except requests.exceptions.TooManyRedirects:\n",
    "        print('TooManyRedirects')\n",
    "        continue                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
    "        # Tell the user their URL was bad and try a different one\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print('RequestException, Catastrophic error!')\n",
    "        # continue\n",
    "        # catastrophic error. bail.\n",
    "        raise SystemExit(e)    \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"request: {e}\")\n",
    "        continue\n",
    "    # print('2')\n",
    "    try:\n",
    "        res = response.json()\n",
    "    except Exception as e:\n",
    "        print(f\"json: {e}\")\n",
    "        continue\n",
    "    # print('3')\n",
    "    try:\n",
    "        fix_price_zones = res['fleets'][0]['vehicle_classes'][0]['price_detail']['base_pricing']['fix_price_detail']\n",
    "    except KeyError as e:\n",
    "        j = j +1\n",
    "        print(f\"{j} Not Fixed Price!\")\n",
    "        continue\n",
    "    except IndexError as e:\n",
    "        print(\"IndexError for fix_price_zones\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"dict: {e}\")\n",
    "        continue\n",
    "    # print('4')\n",
    "    if not isinstance(fix_price_zones,dict):\n",
    "        print(f\"No fix price: {fix_price_zones}\")\n",
    "    else:\n",
    "        try:\n",
    "            route = (fix_price_zones['from'], fix_price_zones['to'],pt._mapping['dispatch_id'])\n",
    "            fix_zone_routes_list.append(route)\n",
    "            # ins = insert(fixed_zone_routes).values(\n",
    "            #     start=fix_price_zones['from'], end=fix_price_zones['from'], dispatch_id= pt._mapping['dispatch_id'])\n",
    "            i = i +1\n",
    "        except KeyError as e:\n",
    "            print(\"KeyError for route\")\n",
    "            continue\n",
    "\n",
    "        # print('5')\n",
    "        if i%50 == 0:\n",
    "            # connection.execute(ins)\n",
    "            df = pd.DataFrame(fix_zone_routes_list, columns=['start', 'end', 'dispatch_id'])\n",
    "            df.to_sql('fixed_zone_routes', sqlite_eng, if_exists='append')\n",
    "            fix_zone_routes_list = []\n",
    "            print(f\"Created {i} records\")\n",
    "\n",
    "    # print('6')\n",
    "df = pd.DataFrame(fix_zone_routes_list, columns=['start', 'end', 'dispatch_id'])\n",
    "df.to_sql('fixed_zone_routes', sqlite_eng, if_exists='append')\n",
    "fix_zone_routes_list = []\n",
    "print(f\"Created {i} records\")\n",
    "    # print('6')\n",
    "    # print(pt._mapping['ride_id'], pt._mapping['dispatch_amount'], pt._mapping['dispatch_currency'])\n",
    "    # # print(pt._mapping['start_place'])\n",
    "    # print(pt._mapping['start_lng'], pt._mapping['start_ltt'])\n",
    "    # # print(pt._mapping['end_place']) \n",
    "    # print(pt._mapping['end_lng'], pt._mapping['end_ltt'])\n",
    "    # print(\"------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_zone_routes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_training_q = session.query(price_training_t).limit(10)\n",
    "ride_samples = []\n",
    "for pt in price_training_q:\n",
    "    ride_samples.append(pt)\n",
    "    print(pt._mapping['ride_id'], pt._mapping['dispatch_amount'], pt._mapping['dispatch_currency'])\n",
    "    # print(pt._mapping['start_place'])\n",
    "    print(pt._mapping['start_lng'], pt._mapping['start_ltt'])\n",
    "    # print(pt._mapping['end_place']) \n",
    "    print(pt._mapping['end_lng'], pt._mapping['end_ltt'])\n",
    "    print(\"------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ride_samples[0]._mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(ride_samples)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rides_q = session.query(price_training_t).limit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for ride in rides_q:\n",
    "    print(ride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rides_q = session.query(ride_ride_t).limit(10)\n",
    "for ride in rides_q:\n",
    "    print(ride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(price_training_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use core to retrieve records\n",
    "# rp = connection.execute(price_training_t)\n",
    "# for i, record in enumerate(rp):\n",
    "#     print(i, record.ride_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = rp.fetchall()\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_sql(price_training_t, engine)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlite_eng = create_engine('sqlite:///../data/price_training_from_gbq_raw.db', echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql('price_training_orlando_mpv5', sqlite_eng, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traffic peak time exclusion\n",
    "source https://www.quora.com/What-is-the-trickiest-time-of-the-day-to-drive-in-Orlando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workalendar.usa import Florida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_orlando = Florida()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_dates = [d[0] for d in cal_orlando.holidays(2024)]\n",
    "exclude_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workalendar.usa import Florida \n",
    "import numpy as np\n",
    "cal_florida = Florida()\n",
    "exclude_dates_str = [str(d[0]) for d in cal_florida.holidays(2024)]\n",
    "exclude_dates_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_dates = [d[0] for d in cal_florida.holidays(2024)]\n",
    "# exclude_dates\n",
    "# res = df['from_datetime_utc'].apply(lambda x: x in exclude_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.any(res.apply(lambda x: x in exclude_dates))\n",
    "# res[0]=True\n",
    "# res\n",
    "# np.any(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pricing.data.utils import validate_datetime_in_iso_format, validate_timezone_in_iana, get_timezone_abbreviation, fix_timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_invalid_datetime = df[df.apply(lambda x: not validate_datetime_in_iso_format(x['from_datetime_fix_str']), axis=1)]\n",
    "df_invalid_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_invalid_timezone = df[df.apply(lambda x: not validate_timezone_in_iana(x['from_timezone_str']), axis=1)]\n",
    "df_invalid_timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#orlando_airport = pd.read_csv('../../data/orlando_all_output.csv')\n",
    "#orlando_airport.head()\n",
    "#orlando_airport.dtypes\n",
    "#orlando_airport.to_sql('orlando_airport', sqlite_eng, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['from_timezone_fix_str'] = df.apply(lambda x: fix_timezone(x['from_timezone_str']), axis=1) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_valid_datetime = df[df.apply(lambda x: validate_datetime_in_iso_format(x['from_datetime_fix_str']), axis=1)]\n",
    "df_valid_timezone = df_valid_datetime[df_valid_datetime.apply(lambda x: validate_timezone_in_iana(x['from_timezone_fix_str']), axis=1)]\n",
    "df_valid_timezone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_valid_timezone.loc[df_invalid_timezone.index, ['from_timezone_str', 'from_timezone_fix_str']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "df_utc_offset = (df_valid_timezone.apply(lambda x: datetime.now(pytz.timezone(x['from_timezone_fix_str'])), axis=1)\n",
    "                            .apply(lambda x: x.strftime('%z')))\n",
    "df_utc_offset.name = 'utc_offset'\n",
    "df_utc_offset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dt_str = df_valid_timezone['from_datetime_fix_str']\n",
    "df_valid_timezone['from_datetime_local'] = df_valid_timezone.apply(lambda x: (pd.to_datetime(x['from_datetime_fix_str']).to_datetime64()), axis=1)\n",
    "df_valid_timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_timezone.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df_valid_timezone['from_datetime_local_tz'] = df_valid_timezone.apply(lambda x: pytz.timezone(x.loc[:,'from_timezone_str']).localize(x.loc[:,'from_datetime_local']), axis=1)\n",
    "df_valid_timezone['from_timezone'] = df_valid_timezone.apply(lambda x: pytz.timezone(x['from_timezone_fix_str']), axis=1)\n",
    "df_valid_timezone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_timezone['from_datetime_tz'] = df_valid_timezone.apply(lambda x: x['from_timezone'].localize(x['from_datetime_local']), axis=1)\n",
    "df_valid_timezone\n",
    "                                    # .apply(lambda x: x.localize(x.loc[:,'from_timezone_str']), axis=1))\n",
    "# df_valid_timezone\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filtering out peak traffic time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_time_str = [('07:00:00', '09:00:00'), ('16:00:00', '19:00:00')]\n",
    "night_time_str = [('22:00:00', '6:00:00')]  # Shanghai, US usually no overtime extra fees New York 8pm ~ 6am\n",
    "ind = []\n",
    "td = []\n",
    "for pt in peak_time_str:\n",
    "    ind.append(pd.DatetimeIndex(pt))\n",
    "ind\n",
    "for i in ind:\n",
    "    i[1]-i[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_time = []\n",
    "for pt in peak_time_str:\n",
    "    peak_time.append(pd.date_range(pt[0], pt[1], freq='h'))\n",
    "for pt in peak_time:\n",
    "    print(pt, pt.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_time_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_peak_traffic_time = df_valid_timezone[\n",
    "    df_valid_timezone['from_datetime_tz'].apply(lambda x: x.strftime('%H:%M:%S')).between(*peak_time_str[0])\n",
    "    | df_valid_timezone['from_datetime_tz'].apply(lambda x: x.strftime('%H:%M:%S')).between(*peak_time_str[1])\n",
    "]\n",
    "df_peak_traffic_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_out_of_peak_traffic_time = df_valid_timezone[\n",
    "    ~ (df_valid_timezone['from_datetime_tz'].apply(lambda x: x.strftime('%H:%M:%S')).between(*peak_time_str[0])\n",
    "    | df_valid_timezone['from_datetime_tz'].apply(lambda x: x.strftime('%H:%M:%S')).between(*peak_time_str[1]))\n",
    "]\n",
    "df_out_of_peak_traffic_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df_utc_offset = (df_valid_timezone.apply(lambda x: datetime.now(pytz.timezone(x.loc['timezone'])))\n",
    "#                             .apply(lambda x: x.strftime('%z')))\n",
    "# df_utc_offset.name = 'utc_offset'\n",
    "# df_utc_offset\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filter out round trip (time reservation) with feature distance = 1 (m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_round_trip = df_valid_timezone[df_valid_timezone['distance'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = df_no_round_trip.loc[:,['ride_id', 'trip_type', 'trip_no', 'trip_count', 'ride_status', 'partner', 'fleet', \n",
    "                'start_place', 'end_place',\n",
    "                'passenger_count', 'luggage_count',\n",
    "                'dispatch_amount', 'dispatch_currency',\n",
    "                'distance', 'duration', 'vehicle_class', \n",
    "                'from_datetime_tz']]\n",
    " \n",
    "df_training['cent_price_per_km'] = df_training['dispatch_amount'] / df_training['distance']*100.0\n",
    "df_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_cent_per_km(x):\n",
    "    x['average_cent_per_km'] = x['cent_price_per_km'].mean()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fleet_trip_no(x):\n",
    "    x['fleet_trip_count'] = len(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fleet_statistics = df_training.loc[:, ['ride_id','fleet']]\n",
    "df_fleet_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_fleet_trip_no = df_fleet_statistics.groupby('fleet').aggregate([len])\n",
    "df_fleet_trip_no.sort_values(by=('ride_id', 'len'), ascending=False, inplace=True)\n",
    "df_fleet_trip_no\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_big_fleets = df_fleet_trip_no[df_fleet_trip_no[('ride_id','len')] >100]\n",
    "df_big_fleets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_big_fleet_data = []\n",
    "for f in df_big_fleets.index:\n",
    "    print(f)\n",
    "    df_big_fleet_data.append(df_training[df_training['fleet'] == f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_big_fleet_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_big_fleet_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_big_fleet_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df_training['average_cent_per_km'] = df_training.groupby('fleet').apply(average_cent_per_km)\n",
    "df_analysis = df_training.groupby('fleet').apply(average_cent_per_km)\n",
    "df_analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
