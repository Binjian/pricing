{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core data utilities\n",
    "\n",
    "> core utilities for data processing: \n",
    "> datetime processing, time zone processing, validity, filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp data.database.deduplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from asyncio import as_completed\n",
    "from threading import Thread\n",
    "\n",
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import pytz\n",
    "#| export\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision reduction for start_ltt, start_lng, end_ltt, end_lng and pick distinct values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from sqlalchemy import create_engine, select, func, distinct, MetaData, Table, update, bindparam, Column, insert, desc, asc, and_, or_, not_, Numeric, cast, func\n",
    "from sqlalchemy.orm import sessionmaker, aliased\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_eng = create_engine('sqlite:///../data/price_training_raw.db', echo=False)\n",
    "conn = sql_eng.connect()\n",
    "my_table = Table('price_training_raw_2024_usd', MetaData(), autoload_with=sql_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = select(func.count(distinct(my_table.c.dispatch_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sql_eng.connect() as connection:\n",
    "    result = connection.execute(query)\n",
    "    unique_count = result.scalar()\n",
    "    \n",
    "print(unique_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = select(my_table).limit(10)\n",
    "df = pd.read_sql(query, conn, index_col='dispatch_id')\n",
    "# df[['route_start','route_end']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# order by start_ltt, start_lng, end_ltt, end_lng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_eng = create_engine('sqlite:///../data/price_training_raw.db', echo=False)\n",
    "conn = sql_eng.connect()\n",
    "metadata = MetaData()\n",
    "my_table = Table('price_training_raw_2024_usd', metadata, autoload_with=sql_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.reflect(bind=sql_eng)\n",
    "raw_t = metadata.tables['price_training_raw_2024_usd']\n",
    "s = select(raw_t).limit(10)\n",
    "rp = sql_eng.connect().execute(s)\n",
    "df = pd.DataFrame(rp)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create new table with latitutde and longitude reduced to 5 decimal places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_t = select(my_table).where(\n",
    "    and_(\n",
    "        my_table.c.start_ltt.isnot(None),\n",
    "        my_table.c.start_lng.isnot(None),\n",
    "        my_table.c.end_ltt.isnot(None),\n",
    "        my_table.c.end_lng.isnot(None),\n",
    "    )\n",
    ").order_by(asc(my_table.c.start_ltt), asc(my_table.c.start_ltt))\n",
    "ordered_t = ordered_t.select_from(my_table)\n",
    "ordered_t = ordered_t.alias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordered_t = ordered_t.limit(10)\n",
    "# df = pd.read_sql(ordered_t.limit(10),sql_eng)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_ltt_lng_t = select(ordered_t.c.dispatch_id,\n",
    "                      cast(ordered_t.c.start_ltt, Numeric(9,5)).label('start_ltt_lp'),\n",
    "                      cast(ordered_t.c.start_lng, Numeric(9,5)).label('start_lng_lp'),\n",
    "                      cast(ordered_t.c.end_ltt, Numeric(9,5)).label('end_ltt_lp'),\n",
    "                      cast(ordered_t.c.end_lng, Numeric(9,5)).label('end_lng_lp'))\n",
    "lp_ltt_lng_t = lp_ltt_lng_t.select_from(ordered_t)\n",
    "lp_ltt_lng_t = lp_ltt_lng_t.alias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_sql(lp_ltt_lng_t, sql_eng)\n",
    "# df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_start_lp_t = select(lp_ltt_lng_t.c.dispatch_id, \n",
    "                         lp_ltt_lng_t.c.start_ltt_lp,\n",
    "                         # func.max(lp_ltt_lng_t.c.start_ltt_lp).label('unique_start_ltt_lp'), \n",
    "                         # func.max(lp_ltt_lng_t.c.start_lng_lp).label('unique_start_lng_lp'),\n",
    "                         lp_ltt_lng_t.c.start_lng_lp, \n",
    "                         lp_ltt_lng_t.c.end_ltt_lp,\n",
    "                         lp_ltt_lng_t.c.end_lng_lp\n",
    "                         ).group_by(lp_ltt_lng_t.c.start_ltt_lp).distinct(lp_ltt_lng_t.c.start_lng_lp)#.subquery()\n",
    "distinct_start_lp_t = distinct_start_lp_t.alias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_sql(distinct_start_lp_t, sql_eng)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "distinct_end_lp_t = select(lp_ltt_lng_t.c.dispatch_id, \n",
    "                         lp_ltt_lng_t.c.start_ltt_lp,\n",
    "                         lp_ltt_lng_t.c.start_lng_lp,\n",
    "                         lp_ltt_lng_t.c.end_ltt_lp,\n",
    "                         lp_ltt_lng_t.c.end_lng_lp\n",
    "                         ).group_by(lp_ltt_lng_t.c.end_ltt_lp).distinct(lp_ltt_lng_t.c.end_lng_lp)\n",
    "distinct_end_lp_t = distinct_end_lp_t.alias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df = pd.read_sql(distinct_end_lp_t, sql_eng)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_zone_start_t = select(\n",
    "    ordered_t.c, \n",
    "    distinct_start_lp_t.c.start_ltt_lp, \n",
    "    distinct_start_lp_t.c.start_lng_lp, \n",
    "    distinct_start_lp_t.c.end_ltt_lp, \n",
    "    distinct_start_lp_t.c.end_lng_lp\n",
    "    ).select_from(ordered_t\n",
    "                  .join(distinct_start_lp_t, \n",
    "                        ordered_t.c.dispatch_id == distinct_start_lp_t.c.dispatch_id))\n",
    "df_start = pd.read_sql(fp_zone_start_t, sql_eng)\n",
    "df_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_start.to_sql('price_training_raw_2024_usd_start_deduplicated', sql_eng, if_exists='replace', index=True)\n",
    "# df_start.to_csv('../data/price_training_raw_2024_usd_start_deduplicated.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_zone_end_t = select(\n",
    "    ordered_t.c,\n",
    "    distinct_end_lp_t.c.start_ltt_lp,\n",
    "    distinct_end_lp_t.c.start_lng_lp,\n",
    "    distinct_end_lp_t.c.end_ltt_lp,\n",
    "    distinct_end_lp_t.c.end_lng_lp\n",
    ").select_from(ordered_t\n",
    "              .join(distinct_end_lp_t, \n",
    "                    ordered_t.c.dispatch_id == distinct_end_lp_t.c.dispatch_id)\n",
    "              )\n",
    "df_end = pd.read_sql(fp_zone_end_t, sql_eng)\n",
    "df_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_end.to_sql('price_training_raw_2024_usd_end_deduplicated', sql_eng, if_exists='replace', index=True)\n",
    "# df_end.to_csv('../data/price_training_raw_2024_usd_end_deduplicated.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://j1j495o5pk.execute-api.us-east-2.amazonaws.com/upncoming/ride-pricings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_list = ['../data/price_training_raw_2024_usd_start_deduplicated.csv',\n",
    "             '../data/price_training_raw_2024_usd_end_deduplicated.csv']\n",
    "csv_result_file_list = ['../data/price_training_raw_2024_usd_start_result_deduplicated.csv',\n",
    "                 '../data/price_training_raw_2024_usd_end_result_deduplicated.csv']\n",
    "total_rows = [df_start.shape[0], df_end.shape[0]]\n",
    "result_csv = '../data/dispatch_fixed_zones_label_list.csv'\n",
    "total_rows\n",
    "\n",
    "chunk_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fixed_zone_one(start_ltt, start_lng, end_ltt, end_lng):\n",
    "    params = {\n",
    "        'from_lat': start_ltt,\n",
    "        'from_lng': start_lng,\n",
    "        'to_lat': end_ltt,\n",
    "        'to_lng': end_lng,\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url=url, params=params)\n",
    "    except requests.exceptions.Timeout:\n",
    "        print('Timeout')\n",
    "        return None\n",
    "    except requests.exceptions.TooManyRedirects:\n",
    "        print('TooManyRedirects')\n",
    "        return None\n",
    "        # Tell the user their URL was bad and try a different one\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print('RequestException, Catastrophic error!')\n",
    "        return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"request: {e}\")\n",
    "        return None\n",
    "    # print('2')\n",
    "    try:\n",
    "        res = response.json()\n",
    "    except Exception as e:\n",
    "        print(f\"json: {e}\")\n",
    "        return None\n",
    "    # print('3')\n",
    "    try:\n",
    "        fix_price_zones = res['fleets'][0]['vehicle_classes'][0]['price_detail']['base_pricing']['fix_price_detail']\n",
    "    except KeyError as e:\n",
    "        print(f\"No Fixed Price!\")\n",
    "        return None\n",
    "    except IndexError as e:\n",
    "        print(\"IndexError for fix_price_zones\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"dict: {e}\")\n",
    "        return None\n",
    "    # print('4')\n",
    "    if not isinstance(fix_price_zones,dict):\n",
    "        print(f\"No fix price: {fix_price_zones}\")\n",
    "        return None\n",
    "    else:\n",
    "        try:\n",
    "            return {'from': fix_price_zones['from'], 'to': fix_price_zones['to']}\n",
    "        except KeyError as e:\n",
    "            print(\"KeyError for route\")\n",
    "            return None\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def get_fixed_zone_chunk(chunk):\n",
    "\n",
    "    for i,r in tqdm(chunk.iterrows(),total=chunk_size,desc='chunk progress', leave=False):\n",
    "        fpz = get_fixed_zone_one(r['start_ltt_lp'], r['start_lng_lp'], r['end_ltt_lp'], r['end_lng_lp'])\n",
    "        try:\n",
    "            chunk.at[i, 'route_start'] = fpz['from']\n",
    "            chunk.at[i, 'route_end'] = fpz['to']\n",
    "        except KeyError as e:\n",
    "            print(\"Chunk execption: KeyError for route\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Chunk exception: {e}\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import httpx\n",
    "from http import HTTPStatus\n",
    "from concurrent import futures\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "FZPQueryStatus = Enum('FZPQueryStatus', 'JsonError HTTPXStatusError HTTPXError IndexOrKeyError DictError NoFixedPrice Success')\n",
    "fzp = {'from': None, 'to': None}\n",
    "def get_one_fixed_zone(start_ltt, start_lng, end_ltt, end_lng) -> FZPQueryStatus:\n",
    "    global fzp\n",
    "    params = {\n",
    "        'from_lat': start_ltt,\n",
    "        'from_lng': start_lng,\n",
    "        'to_lat': end_ltt,\n",
    "        'to_lng': end_lng,\n",
    "    }\n",
    "    try:\n",
    "        # response = requests.get(url=url, params=params)\n",
    "        response = httpx.get(url=url, params=params)\n",
    "    except httpx.HTTPStatusError as exc:\n",
    "        return FZPQueryStatus.HTTPXStatusError\n",
    "    except Exception as exc:\n",
    "        return FZPQueryStatus.HTTPXError\n",
    "    \n",
    "    try:\n",
    "        res = response.json()\n",
    "    except Exception as exc:\n",
    "        return FZPQueryStatus.JsonError\n",
    "    try:\n",
    "        fix_price_zones = res['fleets'][0]['vehicle_classes'][0]['price_detail']['base_pricing']['fix_price_detail']\n",
    "    except Exception as exc:\n",
    "        return FZPQueryStatus.IndexOrKeyError\n",
    "    # print('4')\n",
    "    if not isinstance(fix_price_zones,dict):\n",
    "        return FZPQueryStatus.DictError\n",
    "    else:\n",
    "        try:\n",
    "            fzp['from'] = fix_price_zones['from']\n",
    "            fzp['to']   = fix_price_zones['to']\n",
    "            return FZPQueryStatus.Success\n",
    "        except KeyError as e:\n",
    "            return FZPQueryStatus.NoFixedPrice\n",
    "            \n",
    "\n",
    "non_fzp_count = 0\n",
    "max_concurrent = 20\n",
    "for i,chunk in enumerate(tqdm(pd.read_csv(csv_file_list[0],index_col='dispatch_id', chunksize=chunk_size), total=total_rows[0]//chunk_size+1, desc='Overall Progress')):\n",
    "    chunk = chunk.astype({'route_start': str, 'route_end': str})\n",
    "    non_fzp_count_chunk = 0\n",
    "    # get_fixed_zone_chunk(chunk)\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_concurrent) as executor:\n",
    "        to_do_map = {} # list[futures.Future] = [] \n",
    "        # for ind,r in tqdm(chunk.iterrows(),total=chunk_size,desc='chunk progress', leave=False):\n",
    "        for ind,r in chunk.iterrows():\n",
    "            future = executor.submit(get_one_fixed_zone, r['start_ltt_lp'], r['start_lng_lp'], r['end_ltt_lp'], r['end_lng_lp'])\n",
    "            to_do_map[future] = ind\n",
    "        done_iter = as_completed(to_do_map)\n",
    "        done_iter = tqdm(done_iter, total=len(to_do_map), desc='chunk progress', leave=False)\n",
    "        \n",
    "        for future in done_iter:\n",
    "            try:\n",
    "                status = future.result()\n",
    "            except Exception as e:\n",
    "                # print(f\"Exception: {e}\")\n",
    "                continue\n",
    "            \n",
    "            if status == FZPQueryStatus.Success:\n",
    "                ind = to_do_map[future]\n",
    "                try:\n",
    "                    chunk.at[ind, 'route_start'] = fzp['from']\n",
    "                    chunk.at[ind, 'route_end'] = fzp['to']\n",
    "                except KeyError as e:\n",
    "                    non_fzp_count_chunk += 1\n",
    "                    # print(f\"\\r {e}: {non_fzp_count_chunk}/{chunk_size}\")\n",
    "                    continue\n",
    "                except Exception as e:\n",
    "                    non_fzp_count_chunk += 1\n",
    "                    # print(f\"\\r {e}: {non_fzp_count_chunk}/{chunk_size}\")\n",
    "                    continue\n",
    "            else:\n",
    "                non_fzp_count_chunk += 1\n",
    "                # print(f\"\\r non fzp chunk: {non_fzp_count_chunk}/{chunk_size}\")\n",
    "                continue\n",
    "        \n",
    "    non_fzp_count += non_fzp_count_chunk\n",
    "    scanned_row_number = (i+1)*chunk_size\n",
    "    try:\n",
    "        # pd.DataFrame(data=route_list, columns=['dispatch_id', 'rou:w\n",
    "        # te_start', 'route_end']).to_csv(result_csv, mode='a', header=False)\n",
    "        with open(csv_result_file_list[0], 'a') as f:\n",
    "            chunk.to_csv(f, header=f.tell()==0,chunksize=chunk_size)\n",
    "        # chunk.to_csv(path_or_buf=csv_result_file_list[0],mode='a',chunksize=chunk_size)\n",
    "        print(f\"\\r Non_FZP count: {non_fzp_count}/{scanned_row_number}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\r {e}, Non_FZP count: {non_fzp_count}/{scanned_row_number} \")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_one_fixed_zone1(start_ltt, start_lng, end_ltt, end_lng):\n",
    "#     params = {\n",
    "#         'from_lat': start_ltt,\n",
    "#         'from_lng': start_lng,\n",
    "#         'to_lat': end_ltt,\n",
    "#         'to_lng': end_lng,\n",
    "#     }\n",
    "#     try:\n",
    "#         response = requests.get(url=url, params=params)\n",
    "#     except requests.exceptions.Timeout:\n",
    "#         print('Timeout')\n",
    "#         return None\n",
    "#     except requests.exceptions.TooManyRedirects:\n",
    "#         print('TooManyRedirects')\n",
    "#         return None\n",
    "#         # Tell the user their URL was bad and try a different one\n",
    "#     except requests.exceptions.RequestException as e:\n",
    "#         print('RequestException, Catastrophic error!')\n",
    "#         return None\n",
    "# \n",
    "#     except Exception as e:\n",
    "#         print(f\"request: {e}\")\n",
    "#         return None\n",
    "#     # print('2')\n",
    "#     try:\n",
    "#         res = response.json()\n",
    "#     except Exception as e:\n",
    "#         print(f\"json: {e}\")\n",
    "#         return None\n",
    "#     # print('3')\n",
    "#     try:\n",
    "#         fix_price_zones = res['fleets'][0]['vehicle_classes'][0]['price_detail']['base_pricing']['fix_price_detail']\n",
    "#     except KeyError as e:\n",
    "#         # print(f\"No Fixed Price!\")\n",
    "#         return None\n",
    "#     except IndexError as e:\n",
    "#         # print(\"IndexError for fix_price_zones\")\n",
    "#         return None\n",
    "#     except Exception as e:\n",
    "#         # print(f\"dict: {e}\")\n",
    "#         return None\n",
    "#     # print('4')\n",
    "#     if not isinstance(fix_price_zones,dict):\n",
    "#         # print(f\"No fix price: {fix_price_zones}\")\n",
    "#         return None\n",
    "#     else:\n",
    "#         try:\n",
    "#             return {'from': fix_price_zones['from'], 'to': fix_price_zones['to']}\n",
    "#         except KeyError as e:\n",
    "#             # print(\"KeyError for route\")\n",
    "#             return None\n",
    "# \n",
    "# non_fzp_count = 0\n",
    "# for i,chunk in enumerate(tqdm(pd.read_csv(csv_file_list[0],index_col='dispatch_id', chunksize=chunk_size), total=total_rows[0]//chunk_size+1, desc='Overall Progress')):\n",
    "#     chunk = chunk.astype({'route_start': str, 'route_end': str})\n",
    "#     non_fzp_count_chunk = 0\n",
    "#     # get_fixed_zone_chunk(chunk)\n",
    "#     for ind,r in tqdm(chunk.iterrows(),total=chunk_size,desc='chunk progress', leave=False):\n",
    "#         fpz = get_one_fixed_zone1(r['start_ltt_lp'], r['start_lng_lp'], r['end_ltt_lp'], r['end_lng_lp'])\n",
    "#         if fpz is None:\n",
    "#             non_fzp_count_chunk += 1\n",
    "#             # print(f\"\\r non fzp chunk: {non_fzp_count_chunk}/{chunk_size}\")\n",
    "#             continue\n",
    "#         try:\n",
    "#             chunk.at[ind, 'route_start'] = fpz['from']\n",
    "#             chunk.at[ind, 'route_end'] = fpz['to']\n",
    "#         except KeyError as e:\n",
    "#             non_fzp_count_chunk += 1\n",
    "#             # print(f\"\\r {e}: {non_fzp_count_chunk}/{chunk_size}\")\n",
    "#             continue\n",
    "#         except Exception as e:\n",
    "#             non_fzp_count_chunk += 1\n",
    "#             # print(f\"\\r {e}: {non_fzp_count_chunk}/{chunk_size}\")\n",
    "#             continue\n",
    "# \n",
    "#     non_fzp_count += non_fzp_count_chunk\n",
    "#     scanned_row_number = (i+1)*chunk_size\n",
    "#     try:\n",
    "#         # pd.DataFrame(data=route_list, columns=['dispatch_id', 'rou:w\n",
    "#         # te_start', 'route_end']).to_csv(result_csv, mode='a', header=False)\n",
    "#         with open(csv_result_file_list[0], 'a') as f:\n",
    "#             chunk.to_csv(f, header=f.tell()==0,chunksize=chunk_size)\n",
    "#         # chunk.to_csv(path_or_buf=csv_result_file_list[0],mode='a',chunksize=chunk_size)\n",
    "#         print(f\"\\r Non_FZP count: {non_fzp_count}/{scanned_row_number}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"\\r {e}, Non_FZP count: {non_fzp_count}/{scanned_row_number} \")\n",
    "#         continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for chunk in tqdm(pd.read_csv(csv_file_list[0],index_col='dispatch_id', chunksize=chunk_size), total=total_rows[0]//chunk_size+1, desc='Overall Progress'):\n",
    "# # for chunk in pd.read_csv(csv_file_list[0],index_col='dispatch_id', chunksize=chunk_size):\n",
    "#     # [chunk[r] for r in chunk]\n",
    "#     # l = [r for r in chunk.iterrows()]\n",
    "#     # l\n",
    "#     # print(chunk.dtypes)\n",
    "#     # route_list = []\n",
    "#     chunk = chunk.astype({'route_start': str, 'route_end': str})\n",
    "#     for i,r in tqdm(chunk.iterrows(),total=chunk_size,desc='chunk progress', leave=False):\n",
    "#     # for i,r in chunk.iterrows():\n",
    "#         # l = [i, r['start_ltt'], r['start_lng'], r['end_ltt'], r['end_lng']]\n",
    "#         # print(l)\n",
    "#         params = {\n",
    "#             'from_lat': r['start_ltt_lp'],\n",
    "#             'from_lng': r['start_lng_lp'],\n",
    "#             'to_lat': r['end_ltt_lp'],\n",
    "#             'to_lng': r['end_lng_lp'],\n",
    "#         }\n",
    "#         try:\n",
    "#             response = requests.get(url=url, params=params)\n",
    "#         except requests.exceptions.Timeout:\n",
    "#             print('Timeout')\n",
    "#             continue\n",
    "#         except requests.exceptions.TooManyRedirects:\n",
    "#             print('TooManyRedirects')\n",
    "#             continue\n",
    "#             # Tell the user their URL was bad and try a different one\n",
    "#         except requests.exceptions.RequestException as e:\n",
    "#             print('RequestException, Catastrophic error!')\n",
    "#             continue\n",
    "#             # catastrophic error. bail.\n",
    "#             # raise SystemExit(e)\n",
    "# \n",
    "#         except Exception as e:\n",
    "#             print(f\"request: {e}\")\n",
    "#             continue\n",
    "#         # print('2')\n",
    "#         try:\n",
    "#             res = response.json()\n",
    "#         except Exception as e:\n",
    "#             print(f\"json: {e}\")\n",
    "#             continue\n",
    "#         # print('3')\n",
    "#         try:\n",
    "#             fix_price_zones = res['fleets'][0]['vehicle_classes'][0]['price_detail']['base_pricing']['fix_price_detail']\n",
    "#         except KeyError as e:\n",
    "#             print(f\"No Fixed Price!\")\n",
    "#             continue\n",
    "#         except IndexError as e:\n",
    "#             print(\"IndexError for fix_price_zones\")\n",
    "#             continue\n",
    "#         except Exception as e:\n",
    "#             print(f\"dict: {e}\")\n",
    "#             continue\n",
    "#         # print('4')\n",
    "#         if not isinstance(fix_price_zones,dict):\n",
    "#             print(f\"No fix price: {fix_price_zones}\")\n",
    "#         else:\n",
    "#             try:\n",
    "#                 # route_list.append((i, fix_price_zones['from'], fix_price_zones['to']))\n",
    "#                 # fix_zone_routes_list.append(route)\n",
    "#                 chunk.at[i, 'route_start'] = fix_price_zones['from']\n",
    "#                 chunk.at[i, 'route_end'] = fix_price_zones['to']\n",
    "#                 # ins = insert(fixed_zone_routes).values(\n",
    "#                 #     start=fix_price_zones['from'], end=fix_price_zones['from'], dispatch_id= pt        ._mapping['dispatch_id'])\n",
    "#                 # stmt = (\n",
    "#                 #     update(raw)  # 'raw' is your table object\n",
    "#                 #     .where(raw.c.dispatch_id == int(i))\n",
    "#                 #     .values(\n",
    "#                 #         route_start = fix_price_zones['from'],\n",
    "#                 #         route_end = fix_price_zones['to']\n",
    "#                 #     )\n",
    "#                 # )\n",
    "#                 # conn.execute(stmt)\n",
    "#                 # conn.commit()\n",
    "#             except KeyError as e:\n",
    "#                 print(\"KeyError for route\")\n",
    "#                 continue\n",
    "#     \n",
    "#     try:\n",
    "#         # pd.DataFrame(data=route_list, columns=['dispatch_id', 'route_start', 'route_end']).to_csv(result_csv, mode='a', header=False)\n",
    "#         chunk.to_csv(path_or_buf=csv_result_file_list[0],mode='a',chunksize=chunk_size)\n",
    "#     except Exception as e:\n",
    "#         print(f\"csv: {e}\")\n",
    "#         continue\n",
    "#     \n",
    "#     # with sqlite_eng.begin() as conn:\n",
    "#     #     conn.execute(\n",
    "#     #         stmt, \n",
    "#     #         [\n",
    "#     #             {\n",
    "#     #                 'b_dispatch_id': i,\n",
    "#     #                 'route_start': r['route_start'],\n",
    "#     #                 'route_end': r['route_end']\n",
    "#     #             }\n",
    "#     #             for i,r in chunk.iterrows()\n",
    "#     #         ],\n",
    "#     #     )\n",
    "#     #     conn.commit()\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query FP-Server and add label to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_columns = [Column(col.name, col.type, primary_key=col.primary_key) for col in my_table.columns]\n",
    "# new_table = Table('price_training_raw_2024_usd_reordered', metadata, *new_columns)\n",
    "# new_table.create(sql_eng)\n",
    "new_table = Table('price_training_raw_2024_usd_reordered', metadata, autoload_with=sql_eng)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Session = sessionmaker(bind=sql_eng)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## insert data into new table: fp_zone_start_t & fp_zone_end_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 1000\n",
    "total_rows = len(ordered_rows)\n",
    "total_rows\n",
    "total = total_rows//chunk_size+1\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in tqdm(range(total), total=total, desc='Overall Processing'):\n",
    "    start = chunk*chunk_size\n",
    "    end = (chunk+1)*chunk_size\n",
    "    if end > total_rows:\n",
    "        end = total_rows\n",
    "    chunk_data = ordered_rows[start:end]\n",
    "    batch = [dict(zip(cols,row)) for row in chunk_data]\n",
    "    result = session.execute(insert(new_table).values(batch))\n",
    "    session.commit()\n",
    "    # for row in tqdm(chunk_data, total=len(chunk_data), desc='Chunk Processing'):\n",
    "    #     session.execute(new_table.insert().values(row))\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=ordered_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(fp_zone_t, sql_eng)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distinct_t = select(distinct(lp_ltt_lng_t.c.start_lng_lp))\n",
    "# distinct_t = distinct_t.limit(1000)#.distinct(lp_ltt_lng_t.c.start_ltt)\n",
    "# df = pd.read_sql(distinct_t, sql_eng)\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new table with ordered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_t = select(my_table).where(\n",
    "    and_(\n",
    "        my_table.c.start_ltt.isnot(None),\n",
    "        my_table.c.start_lng.isnot(None),\n",
    "    )\n",
    ").order_by(asc(my_table.c.start_ltt), asc(my_table.c.start_ltt))\n",
    "ordered_t = ordered_t.select_from(my_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sql_eng.connect() as connection:\n",
    "    result = connection.execute(ordered_t)\n",
    "    ordered_rows = result.fetchall()\n",
    "# ordered_rows[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ordered_rows[:10]\n",
    "cols = [c.name for c in ordered_t.subquery().columns]\n",
    "df = pd.DataFrame(data=data, columns=cols)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch = [dict(zip(cols, row)) for row in data]\n",
    "batch[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in tqdm(result, total=unique_count):\n",
    "    for chunk in tqdm(pd.read_sql(query.statement, conn, index_col='dispatch_id', chunksize=chunk_size), total=total_rows//chunk_size+1, desc='Overall Processing'):\n",
    "    route_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sql_eng.connect() as conn:\n",
    "    result = conn.execute(ordered_t)\n",
    "    for row in tqdm(result, total=unique_count):\n",
    "        session.execute(new_table.insert().values(row))\n",
    "    session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(my_table.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata_new = MetaData()\n",
    "# my_table.to_metadata(metadata_new)\n",
    "# metadata_new.tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_table = Table('price_training_raw_2024_usd_geo_ordered', metadata, *my_table.columns)\n",
    "# list(new_table.columns)\n",
    "# new_table.name = 'price_training_raw_2024_usd_geo_ordered'\n",
    "# metadata_new.create_all(sql_eng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reduce precision of start_ltt, start_lng, end_ltt, end_lng by 3 digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'route_start'] = 'start'\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stmt = (\n",
    "    update(my_table)  # 'raw' is your table object\n",
    "    .where(my_table.c.dispatch_id == 822019)\n",
    "    .values(\n",
    "        route_start='New Zone C',\n",
    "        route_end='New Zone D'\n",
    "    )\n",
    ")\n",
    "print(stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled = stmt.compile()\n",
    "compiled.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sql_eng.connect() as conn:\n",
    "    result = conn.execute(stmt)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = select(my_table).where(my_table.c.dispatch_id == 822019)\n",
    "rp = sql_eng.connect().execute(s)\n",
    "results = rp.fetchall()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,r in df.iterrows():\n",
    "    l = [i, r['ride_id'], r['dispatch_amount'],r['fleet']]\n",
    "    # print(r)\n",
    "    df.at[i,'route_end'] = 'Shanghai'\n",
    "    stmt = (\n",
    "        update(my_table)\n",
    "        .where(my_table.c.dispatch_id == int(i))\n",
    "        .values(\n",
    "            route_start='Beijing',\n",
    "            route_end='Shanghai',\n",
    "        )\n",
    "    )\n",
    "    with sql_eng.connect() as conn:\n",
    "        conn.execute(stmt)\n",
    "        conn.commit()\n",
    "    # print('----')\n",
    "    print(l)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update data batchwise in sqlite db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'route_start'] = 'Zone 0'\n",
    "df.loc[:,'route_end'] = 'Zone 1'\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = (\n",
    "    update(my_table)  # 'raw' is your table object\n",
    "    .where(my_table.c.dispatch_id == bindparam('b_dispatch_id'))\n",
    "    .values(\n",
    "        route_start=bindparam('route_start'),\n",
    "        route_end=bindparam('route_end')\n",
    "    )\n",
    ")\n",
    "print(stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [ \n",
    "            {'dispatch_id': i,\n",
    "             'route_start': r['route_start'],\n",
    "             'route_end': r['route_end']} \n",
    "            for i,r in df.iterrows()\n",
    "        ]\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with sql_eng.begin() as conn:\n",
    "    conn.execute(\n",
    "        stmt,\n",
    "        [ \n",
    "            {'b_dispatch_id': i,\n",
    "             'route_start': r['route_start'],\n",
    "             'route_end': r['route_end']} \n",
    "            for i,r in df.iterrows()\n",
    "        ],\n",
    "    )\n",
    "    conn.commit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = select(my_table).limit(20)\n",
    "rp = sql_eng.connect().execute(s)\n",
    "results = rp.fetchall()\n",
    "df = pd.DataFrame(results)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,r in df.iterrows():\n",
    "    print(i, r['ride_id'], r['dispatch_amount'],r['fleet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df.to_sql('price_training_raw_2024_usd', sqlite_eng, if_exists= 'replace',index=True, index_label='dispatch_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for r in df.itertuples():\n",
    "    # print(r)\n",
    "    print(r.ride_id, r.fleet)\n",
    "    df.at[r.Index, 'route_start'] = 'PVG'\n",
    "    # r.route_start = 'start'\n",
    "    # r.route_end = 'end'\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df.to_sql('price_training_raw_2024_usd', sqlite_eng, if_exists= 'replace',index=True, index_label='dispatch_id')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
