{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data database scraper\n",
    "> database scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp data.database.scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from pyasn1_modules.rfc3279 import id_fieldType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from sqlalchemy import MetaData, create_engine, asc, desc, and_, or_, not_, case, extract, cast, text, distinct, Column, update, bindparam\n",
    "from sqlalchemy.types import DateTime, Date, Time, String\n",
    "from sqlalchemy.schema import *\n",
    "from sqlalchemy.sql import func as F, Selectable, select\n",
    "from sqlalchemy.dialects import registry\n",
    "from sqlalchemy.engine.row import Row\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy.orm import sessionmaker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import requests\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from google.oauth2 import service_account\n",
    "from google.oauth2.service_account import Credentials\n",
    "from geopy.timezone import from_timezone_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from google.cloud import bigquery\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = os.getenv('GC_QUOTE_API_CREDENTIALS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credential = service_account.Credentials.from_service_account_file(\"../\" + key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registry.register('bigquery', 'sqlalchemy_bigquery', 'BigQueryDialect')\n",
    "engine = create_engine('bigquery://quote-api-365206',\n",
    "                       credentials_path='../' + key,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = MetaData()\n",
    "def get_table(project_name: str, dataset_name: str, table_name: str)-> Table:\n",
    "    table = Table(f'{project_name}.{dataset_name}.{table_name}', metadata, autoload_with=engine)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = engine.connect()\n",
    "connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# local table from local sqlite database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_from_date = '2024-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_eng = create_engine('sqlite:///../data/price_training_raw.db', echo=False)\n",
    "conn = sql_eng.connect()\n",
    "metadata = MetaData()\n",
    "raw = Table('price_training_raw_2024_usd', metadata, autoload_with=sql_eng)\n",
    "Session = sessionmaker(bind=sql_eng)\n",
    "session = Session()\n",
    "chunk_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata2 = MetaData()\n",
    "fix_zones = Table('price_training_dispatch_fixed_zones', metadata2, autoload_with=sql_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rows = session.query(raw).count()\n",
    "total_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inserted two new columns for fixed price zone start_zone and end_zone when creating sql table from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # engine.execute('ALTER TABLE price_training_raw ADD COLUMN start_zone TEXT')\n",
    "# # engine.execute('ALTER TABLE price_training_raw ADD COLUMN end_zone TEXT')\n",
    "# start_zone_column = Column('start_zone', String)\n",
    "# end_zone_column = Column('end_zone', String)\n",
    "# add_column_op = AddColumn(start_zone_column, raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = 'https://j1j495o5pk.execute-api.us-east-2.amazonaws.com/upncoming/ride-pricings'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the table in chunks\n",
    "query = session.query(raw)\n",
    "chunk_size =1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_stmt = (\n",
    "    update(raw)  # 'raw' is your table object\n",
    "    .where(raw.c.dispatch_id == bindparam('b_dispatch_id'))\n",
    "    .values(\n",
    "        route_start=bindparam('route_start'),\n",
    "        route_end=bindparam('route_end')\n",
    "    )\n",
    ")\n",
    "print(batch_stmt)\n",
    "compiled = batch_stmt.compile()\n",
    "print(compiled.params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_csv = '../data/dispatch_fixed_zones_all.csv'\n",
    "for chunk in tqdm(pd.read_sql(query.statement, conn, index_col='dispatch_id', chunksize=chunk_size), total=total_rows//chunk_size+1, desc='Overall Processing'):\n",
    "    # [chunk[r] for r in chunk]\n",
    "    # l = [r for r in chunk.iterrows()]\n",
    "    # l\n",
    "    # print(chunk.dtypes)\n",
    "    route_list = []\n",
    "    for i,r in tqdm(chunk.iterrows(),total=chunk_size, desc='Chunk Processing', leave=False):\n",
    "        # l = [i, r['start_ltt'], r['start_lng'], r['end_ltt'], r['end_lng']]\n",
    "        # print(l)\n",
    "        params = {\n",
    "            'from_lat': r['start_ltt'],\n",
    "            'from_lng': r['start_lng'],\n",
    "            'to_lat': r['end_ltt'],\n",
    "            'to_lng': r['end_lng'],\n",
    "        }\n",
    "        try:\n",
    "            response = requests.get(url=url, params=params)\n",
    "        except requests.exceptions.Timeout:\n",
    "            print('Timeout')\n",
    "            continue\n",
    "        except requests.exceptions.TooManyRedirects:\n",
    "            print('TooManyRedirects')\n",
    "            continue\n",
    "            # Tell the user their URL was bad and try a different one\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print('RequestException, Catastrophic error!')\n",
    "            continue\n",
    "            # catastrophic error. bail.\n",
    "            # raise SystemExit(e)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"request: {e}\")\n",
    "            continue\n",
    "        # print('2')\n",
    "        try:\n",
    "            res = response.json()\n",
    "        except Exception as e:\n",
    "            print(f\"json: {e}\")\n",
    "            continue\n",
    "        # print('3')\n",
    "        try:\n",
    "            fix_price_zones = res['fleets'][0]['vehicle_classes'][0]['price_detail']['base_pricing']['fix_price_detail']\n",
    "        except KeyError as e:\n",
    "            print(f\"No Fixed Price!\")\n",
    "            continue\n",
    "        except IndexError as e:\n",
    "            print(\"IndexError for fix_price_zones\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"dict: {e}\")\n",
    "            continue\n",
    "        # print('4')\n",
    "        if not isinstance(fix_price_zones,dict):\n",
    "            print(f\"No fix price: {fix_price_zones}\")\n",
    "        else:\n",
    "            try:\n",
    "                route_list.append((i, fix_price_zones['from'], fix_price_zones['to']))\n",
    "                # fix_zone_routes_list.append(route)\n",
    "                # chunk.at[i, 'route_start'] = fix_price_zones['from']\n",
    "                # chunk.at[i, 'route_end'] = fix_price_zones['to']\n",
    "                # ins = insert(fixed_zone_routes).values(\n",
    "                #     start=fix_price_zones['from'], end=fix_price_zones['from'], dispatch_id= pt        ._mapping['dispatch_id'])\n",
    "                # stmt = (\n",
    "                #     update(raw)  # 'raw' is your table object\n",
    "                #     .where(raw.c.dispatch_id == int(i))\n",
    "                #     .values(\n",
    "                #         route_start = fix_price_zones['from'],\n",
    "                #         route_end = fix_price_zones['to']\n",
    "                #     )\n",
    "                # )\n",
    "                # conn.execute(stmt)\n",
    "                # conn.commit()\n",
    "            except KeyError as e:\n",
    "                print(\"KeyError for route\")\n",
    "                continue\n",
    "    \n",
    "    try:\n",
    "        pd.DataFrame(data=route_list, columns=['dispatch_id', 'route_start', 'route_end']).to_csv(result_csv, mode='a', header=False)\n",
    "    except Exception as e:\n",
    "        print(f\"csv: {e}\")\n",
    "        continue\n",
    "    \n",
    "    # with sqlite_eng.begin() as conn:\n",
    "    #     conn.execute(\n",
    "    #         stmt, \n",
    "    #         [\n",
    "    #             {\n",
    "    #                 'b_dispatch_id': i,\n",
    "    #                 'route_start': r['route_start'],\n",
    "    #                 'route_end': r['route_end']\n",
    "    #             }\n",
    "    #             for i,r in chunk.iterrows()\n",
    "    #         ],\n",
    "    #     )\n",
    "    #     conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result)\n",
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with sql_eng.begin() as conn:\n",
    "    conn.execute(\n",
    "        batch_stmt, \n",
    "        [\n",
    "            {\n",
    "                'b_dispatch_id': i,\n",
    "                'route_start': r['route_start'],\n",
    "                'route_end': r['route_end']\n",
    "            }\n",
    "            for i,r in res.iterrows()\n",
    "        ],\n",
    "    )\n",
    "    conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in pd.read_sql(query.statement, local_conn, chunksize=20):\n",
    "    # [chunk[r] for r in chunk]\n",
    "    # l = [r for r in chunk.iterrows()]\n",
    "    # l\n",
    "    for i,r in chunk.iterrows():\n",
    "        # l = [r[0], r[1]['start_ltt'], r[1]['start_lng'], r[1]['end_ltt'], r[1]['end_lng']]\n",
    "        params = {\n",
    "            'from_lat': r['start_ltt'],\n",
    "            'from_lng': r['start_lng'],\n",
    "            'to_lat': r['end_ltt'],\n",
    "            'to_lng': r['end_lng'],\n",
    "        }\n",
    "        try:\n",
    "            response = requests.get(url=url, params=params)\n",
    "        except requests.exceptions.Timeout:\n",
    "            print('Timeout')\n",
    "            continue\n",
    "        except requests.exceptions.TooManyRedirects:\n",
    "            print('TooManyRedirects')\n",
    "            continue\n",
    "            # Tell the user their URL was bad and try a different one\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print('RequestException, Catastrophic error!')\n",
    "            continue\n",
    "            # catastrophic error. bail.\n",
    "            # raise SystemExit(e)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"request: {e}\")\n",
    "            continue\n",
    "        # print('2')\n",
    "        try:\n",
    "            res = response.json()\n",
    "        except Exception as e:\n",
    "            print(f\"json: {e}\")\n",
    "            continue\n",
    "        # print('3')\n",
    "        try:\n",
    "            fix_price_zones = res['fleets'][0]['vehicle_classes'][0]['price_detail']['base_pricing']['fix_price_detail']\n",
    "        except KeyError as e:\n",
    "            j = j +1\n",
    "            print(f\"{j} Not Fixed Price!\")\n",
    "            continue\n",
    "        except IndexError as e:\n",
    "            print(\"IndexError for fix_price_zones\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"dict: {e}\")\n",
    "            continue\n",
    "        # print('4')\n",
    "        if not isinstance(fix_price_zones,dict):\n",
    "            print(f\"No fix price: {fix_price_zones}\")\n",
    "        else:\n",
    "            try:\n",
    "                # route = (fix_price_zones['from'], fix_price_zones['to'],pt._mapping['dispatch_id'])\n",
    "                # fix_zone_routes_list.append(route)\n",
    "                chunk.at[i, 'route_start']\n",
    "                \n",
    "                # ins = insert(fixed_zone_routes).values(\n",
    "                #     start=fix_price_zones['from'], end=fix_price_zones['from'], dispatch_id= pt        ._mapping['dispatch_id'])\n",
    "                i = i +1\n",
    "            except KeyError as e:\n",
    "                print(\"KeyError for route\")\n",
    "                continue\n",
    "        \n",
    "        price_training_q = session.query(price_training_t).limit(500)\n",
    "fix_zone_routes_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "j = 0\n",
    "for pt in price_training_q:\n",
    "    # print('1')\n",
    "    # ride_samples.append(pt)\n",
    "    params = {\n",
    "        'from_lat': pt._mapping['start_ltt'],\n",
    "        'from_lng': pt._mapping['start_lng'],\n",
    "        'to_lat': pt._mapping['end_ltt'],\n",
    "        'to_lng': pt._mapping['end_lng'],\n",
    "        # 'from_utc':pt._mapping['from_utc'],\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url=url, params=params)\n",
    "    except requests.exceptions.Timeout:\n",
    "        print('Timeout')\n",
    "        continue\n",
    "    except requests.exceptions.TooManyRedirects:\n",
    "        print('TooManyRedirects')\n",
    "        # Tell the user their URL was bad and try a different one\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print('RequestException, Catastrophic error!')\n",
    "        # continue\n",
    "        # catastrophic error. bail.\n",
    "        raise SystemExit(e)    \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"request: {e}\")\n",
    "        continue\n",
    "    # print('2')\n",
    "    try:\n",
    "        res = response.json()\n",
    "    except Exception as e:\n",
    "        print(f\"json: {e}\")\n",
    "        continue\n",
    "    # print('3')\n",
    "    try:\n",
    "        fix_price_zones = res['fleets'][0]['vehicle_classes'][0]['price_detail']['base_pricing']['fix_price_detail']\n",
    "    except KeyError as e:\n",
    "        j = j +1\n",
    "        print(f\"{j} Not Fixed Price!\")\n",
    "        continue\n",
    "    except IndexError as e:\n",
    "        print(\"IndexError for fix_price_zones\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"dict: {e}\")\n",
    "        continue\n",
    "    # print('4')\n",
    "    if not isinstance(fix_price_zones,dict):\n",
    "        print(f\"No fix price: {fix_price_zones}\")\n",
    "    else:\n",
    "        try:\n",
    "            route = (fix_price_zones['from'], fix_price_zones['to'],pt._mapping['dispatch_id'])\n",
    "            fix_zone_routes_list.append(route)\n",
    "            # ins = insert(fixed_zone_routes).values(\n",
    "            #     start=fix_price_zones['from'], end=fix_price_zones['from'], dispatch_id= pt._mapping['dispatch_id'])\n",
    "            i = i +1\n",
    "        except KeyError as e:\n",
    "            print(\"KeyError for route\")\n",
    "            continue\n",
    "\n",
    "        # print('5')\n",
    "        if i%50 == 0:\n",
    "            # connection.execute(ins)\n",
    "            df = pd.DataFrame(fix_zone_routes_list, columns=['start', 'end', 'dispatch_id'])\n",
    "            df.to_sql('fixed_zone_routes', sqlite_eng, if_exists='append')\n",
    "            fix_zone_routes_list = []\n",
    "            print(f\"Created {i} records\")\n",
    "\n",
    "    # print('6')\n",
    "df = pd.DataFrame(fix_zone_routes_list, columns=['start', 'end', 'dispatch_id'])\n",
    "df.to_sql('fixed_zone_routes', sqlite_eng, if_exists='append')\n",
    "fix_zone_routes_list = []\n",
    "print(f\"Created {i} records\")\n",
    "    # print('6')\n",
    "    # print(pt._mapping['ride_id'], pt._mapping['dispatch_amount'], pt._mapping['dispatch_currency'])\n",
    "    # # print(pt._mapping['start_place'])\n",
    "    # print(pt._mapping['start_lng'], pt._mapping['start_ltt'])\n",
    "    # # print(pt._mapping['end_place']) \n",
    "    # print(pt._mapping['end_lng'], pt._mapping['end_ltt'])\n",
    "    # print(\"------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use ORM to retrieve records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_count = session.query(F.count(price_training_t.c.ride_id)).scalar()\n",
    "print(sample_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://j1j495o5pk.execute-api.us-east-2.amazonaws.com/upncoming/ride-pricings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# params = {\n",
    "#     'from_lat': 37.61911449999999,\n",
    "#     'from_lng':-122.3816274,\n",
    "#     'to_lat':37.3635295,\n",
    "#     'to_lng':-121.9285932,\n",
    "#     'from_utc':1727352000,\n",
    "# }\n",
    "# response = requests.get(url=url, params=params)\n",
    "# response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = response.json()\n",
    "# fix_price_zones = res['fleets'][0]['vehicle_classes'][0]['price_detail']['base_pricing']['fix_price_detail']\n",
    "# print(fix_price_zones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ride_samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pt = price_training_q.first()\n",
    "# pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     'from_lat': (pt._mapping['start_ltt']),\n",
    "#     'from_lng': (pt._mapping['start_lng']),\n",
    "#     'to_lat': (pt._mapping['end_ltt']),\n",
    "#     'to_lng': (pt._mapping['end_lng']),\n",
    "#     # 'from_utc': int(pt._mapping['from_utc']),\n",
    "# }\n",
    "# params\n",
    "\n",
    "# response = requests.get(url=url, params=params)\n",
    "# res = response.json()\n",
    "# res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import String,Integer,insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_zone_routes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_training_q = session.query(price_training_t).limit(10)\n",
    "ride_samples = []\n",
    "for pt in price_training_q:\n",
    "    ride_samples.append(pt)\n",
    "    print(pt._mapping['ride_id'], pt._mapping['dispatch_amount'], pt._mapping['dispatch_currency'])\n",
    "    # print(pt._mapping['start_place'])\n",
    "    print(pt._mapping['start_lng'], pt._mapping['start_ltt'])\n",
    "    # print(pt._mapping['end_place']) \n",
    "    print(pt._mapping['end_lng'], pt._mapping['end_ltt'])\n",
    "    print(\"------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ride_samples[0]._mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(ride_samples)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rides_q = session.query(price_training_t).limit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for ride in rides_q:\n",
    "    print(ride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rides_q = session.query(ride_ride_t).limit(10)\n",
    "for ride in rides_q:\n",
    "    print(ride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(price_training_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use core to retrieve records\n",
    "# rp = connection.execute(price_training_t)\n",
    "# for i, record in enumerate(rp):\n",
    "#     print(i, record.ride_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = rp.fetchall()\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_sql(price_training_t, engine)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlite_eng = create_engine('sqlite:///../data/price_training_from_gbq_raw.db', echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql('price_training_orlando_mpv5', sqlite_eng, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traffic peak time exclusion\n",
    "source https://www.quora.com/What-is-the-trickiest-time-of-the-day-to-drive-in-Orlando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workalendar.usa import Florida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_orlando = Florida()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_dates = [d[0] for d in cal_orlando.holidays(2024)]\n",
    "exclude_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workalendar.usa import Florida \n",
    "import numpy as np\n",
    "cal_florida = Florida()\n",
    "exclude_dates_str = [str(d[0]) for d in cal_florida.holidays(2024)]\n",
    "exclude_dates_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_dates = [d[0] for d in cal_florida.holidays(2024)]\n",
    "# exclude_dates\n",
    "# res = df['from_datetime_utc'].apply(lambda x: x in exclude_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.any(res.apply(lambda x: x in exclude_dates))\n",
    "# res[0]=True\n",
    "# res\n",
    "# np.any(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pricing.data.utils import validate_datetime_in_iso_format, validate_timezone_in_iana, get_timezone_abbreviation, fix_timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_invalid_datetime = df[df.apply(lambda x: not validate_datetime_in_iso_format(x['from_datetime_fix_str']), axis=1)]\n",
    "df_invalid_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_invalid_timezone = df[df.apply(lambda x: not validate_timezone_in_iana(x['from_timezone_str']), axis=1)]\n",
    "df_invalid_timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#orlando_airport = pd.read_csv('../../data/orlando_all_output.csv')\n",
    "#orlando_airport.head()\n",
    "#orlando_airport.dtypes\n",
    "#orlando_airport.to_sql('orlando_airport', sqlite_eng, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['from_timezone_fix_str'] = df.apply(lambda x: fix_timezone(x['from_timezone_str']), axis=1) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_valid_datetime = df[df.apply(lambda x: validate_datetime_in_iso_format(x['from_datetime_fix_str']), axis=1)]\n",
    "df_valid_timezone = df_valid_datetime[df_valid_datetime.apply(lambda x: validate_timezone_in_iana(x['from_timezone_fix_str']), axis=1)]\n",
    "df_valid_timezone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_valid_timezone.loc[df_invalid_timezone.index, ['from_timezone_str', 'from_timezone_fix_str']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "df_utc_offset = (df_valid_timezone.apply(lambda x: datetime.now(pytz.timezone(x['from_timezone_fix_str'])), axis=1)\n",
    "                            .apply(lambda x: x.strftime('%z')))\n",
    "df_utc_offset.name = 'utc_offset'\n",
    "df_utc_offset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dt_str = df_valid_timezone['from_datetime_fix_str']\n",
    "df_valid_timezone['from_datetime_local'] = df_valid_timezone.apply(lambda x: (pd.to_datetime(x['from_datetime_fix_str']).to_datetime64()), axis=1)\n",
    "df_valid_timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_timezone.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df_valid_timezone['from_datetime_local_tz'] = df_valid_timezone.apply(lambda x: pytz.timezone(x.loc[:,'from_timezone_str']).localize(x.loc[:,'from_datetime_local']), axis=1)\n",
    "df_valid_timezone['from_timezone'] = df_valid_timezone.apply(lambda x: pytz.timezone(x['from_timezone_fix_str']), axis=1)\n",
    "df_valid_timezone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_timezone['from_datetime_tz'] = df_valid_timezone.apply(lambda x: x['from_timezone'].localize(x['from_datetime_local']), axis=1)\n",
    "df_valid_timezone\n",
    "                                    # .apply(lambda x: x.localize(x.loc[:,'from_timezone_str']), axis=1))\n",
    "# df_valid_timezone\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filtering out peak traffic time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_time_str = [('07:00:00', '09:00:00'), ('16:00:00', '19:00:00')]\n",
    "night_time_str = [('22:00:00', '6:00:00')]  # Shanghai, US usually no overtime extra fees New York 8pm ~ 6am\n",
    "ind = []\n",
    "td = []\n",
    "for pt in peak_time_str:\n",
    "    ind.append(pd.DatetimeIndex(pt))\n",
    "ind\n",
    "for i in ind:\n",
    "    i[1]-i[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_time = []\n",
    "for pt in peak_time_str:\n",
    "    peak_time.append(pd.date_range(pt[0], pt[1], freq='h'))\n",
    "for pt in peak_time:\n",
    "    print(pt, pt.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_time_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_peak_traffic_time = df_valid_timezone[\n",
    "    df_valid_timezone['from_datetime_tz'].apply(lambda x: x.strftime('%H:%M:%S')).between(*peak_time_str[0])\n",
    "    | df_valid_timezone['from_datetime_tz'].apply(lambda x: x.strftime('%H:%M:%S')).between(*peak_time_str[1])\n",
    "]\n",
    "df_peak_traffic_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_out_of_peak_traffic_time = df_valid_timezone[\n",
    "    ~ (df_valid_timezone['from_datetime_tz'].apply(lambda x: x.strftime('%H:%M:%S')).between(*peak_time_str[0])\n",
    "    | df_valid_timezone['from_datetime_tz'].apply(lambda x: x.strftime('%H:%M:%S')).between(*peak_time_str[1]))\n",
    "]\n",
    "df_out_of_peak_traffic_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df_utc_offset = (df_valid_timezone.apply(lambda x: datetime.now(pytz.timezone(x.loc['timezone'])))\n",
    "#                             .apply(lambda x: x.strftime('%z')))\n",
    "# df_utc_offset.name = 'utc_offset'\n",
    "# df_utc_offset\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filter out round trip (time reservation) with feature distance = 1 (m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_round_trip = df_valid_timezone[df_valid_timezone['distance'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = df_no_round_trip.loc[:,['ride_id', 'trip_type', 'trip_no', 'trip_count', 'ride_status', 'partner', 'fleet', \n",
    "                'start_place', 'end_place',\n",
    "                'passenger_count', 'luggage_count',\n",
    "                'dispatch_amount', 'dispatch_currency',\n",
    "                'distance', 'duration', 'vehicle_class', \n",
    "                'from_datetime_tz']]\n",
    " \n",
    "df_training['cent_price_per_km'] = df_training['dispatch_amount'] / df_training['distance']*100.0\n",
    "df_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_cent_per_km(x):\n",
    "    x['average_cent_per_km'] = x['cent_price_per_km'].mean()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fleet_trip_no(x):\n",
    "    x['fleet_trip_count'] = len(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fleet_statistics = df_training.loc[:, ['ride_id','fleet']]\n",
    "df_fleet_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_fleet_trip_no = df_fleet_statistics.groupby('fleet').aggregate([len])\n",
    "df_fleet_trip_no.sort_values(by=('ride_id', 'len'), ascending=False, inplace=True)\n",
    "df_fleet_trip_no\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_big_fleets = df_fleet_trip_no[df_fleet_trip_no[('ride_id','len')] >100]\n",
    "df_big_fleets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_big_fleet_data = []\n",
    "for f in df_big_fleets.index:\n",
    "    print(f)\n",
    "    df_big_fleet_data.append(df_training[df_training['fleet'] == f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_big_fleet_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_big_fleet_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_big_fleet_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df_training['average_cent_per_km'] = df_training.groupby('fleet').apply(average_cent_per_km)\n",
    "df_analysis = df_training.groupby('fleet').apply(average_cent_per_km)\n",
    "df_analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
